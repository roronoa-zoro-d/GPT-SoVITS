2024-08-28 15:21:10,979	INFO worker.py:1743 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
[36m(ProxyActor pid=1396832)[0m INFO 2024-08-28 15:21:15,245 proxy 10.130.253.103 proxy.py:1160 - Proxy starting on node bf0c7bc0bd0337e2c446404717d18799061981b3fcb0586a8a99926e (HTTP port: 7001).
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:21:15,632 controller 1396628 application_state.py:418 - Building application 'app1'.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:21:20,911 controller 1396628 application_state.py:520 - Built application 'app1' successfully.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:21:20,924 controller 1396628 deployment_state.py:1582 - Deploying new version of Deployment(name='SpeakerEmbeddingsRedisRay', app='app1') (initial target replicas: 10).
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:21:20,926 controller 1396628 deployment_state.py:1582 - Deploying new version of Deployment(name='TtsFront', app='app1') (initial target replicas: 10).
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:21:20,928 controller 1396628 deployment_state.py:1582 - Deploying new version of Deployment(name='CosyVoiceWsRay', app='app1') (initial target replicas: 16).
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:21:21,032 controller 1396628 deployment_state.py:1910 - Adding 10 replicas to Deployment(name='SpeakerEmbeddingsRedisRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:21:21,049 controller 1396628 deployment_state.py:1910 - Adding 10 replicas to Deployment(name='TtsFront', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:21:21,056 controller 1396628 deployment_state.py:1910 - Adding 16 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:TtsFront pid=1398076)[0m 2024-08-28 15:21:23,690 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:TtsFront pid=1398076)[0m [2024-08-28 15:21:23,690-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1398076] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:TtsFront pid=1398076)[0m 2024-08-28 15:21:23,690 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:TtsFront pid=1398076)[0m [2024-08-28 15:21:23,690-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1398076]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:TtsFront pid=1398076)[0m 2024-08-28 15:21:23,690 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:TtsFront pid=1398076)[0m [2024-08-28 15:21:23,690-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1398076] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:TtsFront pid=1398074)[0m 2024-08-28 15:21:24,688 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:TtsFront pid=1398074)[0m [2024-08-28 15:21:24,688-wetext-en_normalizer-processor.py-build_fst-95-INFO-1398074] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:TtsFront pid=1398074)[0m 2024-08-28 15:21:24,688 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:TtsFront pid=1398074)[0m [2024-08-28 15:21:24,688-wetext-en_normalizer-processor.py-build_fst-96-INFO-1398074]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:TtsFront pid=1398074)[0m 2024-08-28 15:21:24,688 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:TtsFront pid=1398074)[0m [2024-08-28 15:21:24,688-wetext-en_normalizer-processor.py-build_fst-97-INFO-1398074] skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398093)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398093)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398093)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398093)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:TtsFront pid=1398084)[0m 2024-08-28 15:21:23,911 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 9x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)[0m
[36m(ServeReplica:app1:TtsFront pid=1398084)[0m [2024-08-28 15:21:23,911-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1398084] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 9x across cluster][0m
[36m(ServeReplica:app1:TtsFront pid=1398084)[0m 2024-08-28 15:21:23,911 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 9x across cluster][0m
[36m(ServeReplica:app1:TtsFront pid=1398084)[0m [2024-08-28 15:21:23,911-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1398084]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 9x across cluster][0m
[36m(ServeReplica:app1:TtsFront pid=1398084)[0m 2024-08-28 15:21:23,912 WETEXT INFO skip building fst for zh_normalizer ...[32m [repeated 9x across cluster][0m
[36m(ServeReplica:app1:TtsFront pid=1398084)[0m [2024-08-28 15:21:23,912-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1398084] skip building fst for zh_normalizer ...[32m [repeated 9x across cluster][0m
[36m(ServeReplica:app1:TtsFront pid=1398084)[0m 2024-08-28 15:21:24,876 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 9x across cluster][0m
[36m(ServeReplica:app1:TtsFront pid=1398084)[0m [2024-08-28 15:21:24,876-wetext-en_normalizer-processor.py-build_fst-95-INFO-1398084] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 9x across cluster][0m
[36m(ServeReplica:app1:TtsFront pid=1398084)[0m 2024-08-28 15:21:24,876 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 9x across cluster][0m
[36m(ServeReplica:app1:TtsFront pid=1398084)[0m [2024-08-28 15:21:24,876-wetext-en_normalizer-processor.py-build_fst-96-INFO-1398084]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 9x across cluster][0m
[36m(ServeReplica:app1:TtsFront pid=1398084)[0m 2024-08-28 15:21:24,876 WETEXT INFO skip building fst for en_normalizer ...[32m [repeated 9x across cluster][0m
[36m(ServeReplica:app1:TtsFront pid=1398084)[0m [2024-08-28 15:21:24,876-wetext-en_normalizer-processor.py-build_fst-97-INFO-1398084] skip building fst for en_normalizer ...[32m [repeated 9x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398104)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398104)[0m   warnings.warn([32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398093)[0m [2024-08-28 15:21:37,289-root-flow.py-__init__-45-INFO-1398093] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398093)[0m 2024-08-28 15:21:41.614436736 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398093)[0m 2024-08-28 15:21:41.614481775 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398096)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398096)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398096)[0m [2024-08-28 15:21:37,835-root-flow.py-__init__-45-INFO-1398096] input frame rate=50[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398093)[0m 2024-08-28 15:21:42,651 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398093)[0m [2024-08-28 15:21:42,651-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1398093] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398093)[0m 2024-08-28 15:21:42,652 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398093)[0m [2024-08-28 15:21:42,652-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1398093]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398093)[0m 2024-08-28 15:21:42,652 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398093)[0m [2024-08-28 15:21:42,652-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1398093] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398093)[0m 2024-08-28 15:21:43,587 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398093)[0m [2024-08-28 15:21:43,587-wetext-en_normalizer-processor.py-build_fst-95-INFO-1398093] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398093)[0m 2024-08-28 15:21:43,587 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398093)[0m [2024-08-28 15:21:43,587-wetext-en_normalizer-processor.py-build_fst-96-INFO-1398093]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398093)[0m 2024-08-28 15:21:43,587 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398093)[0m [2024-08-28 15:21:43,587-wetext-en_normalizer-processor.py-build_fst-97-INFO-1398093] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:21:47,036 controller 1396628 deployment_state.py:674 - Exception in Replica(id='kag25vjz', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1398092, ip=10.130.253.103, actor_id=cb6acb0dd1eab1ffab9f119201000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7facb00b5730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 453.77 MiB already allocated; 3.12 MiB free; 454.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:21:47,047 controller 1396628 deployment_state.py:674 - Exception in Replica(id='4ixbl0cs', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1398096, ip=10.130.253.103, actor_id=ffedf20aa303c461bbd9d7a101000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f9a9437b790>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 573.92 MiB already allocated; 3.12 MiB free; 574.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:21:47,049 controller 1396628 deployment_state.py:674 - Exception in Replica(id='z0mk9srm', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1398099, ip=10.130.253.103, actor_id=a072c4e9967edfb3012e81c801000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f2898135700>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 453.77 MiB already allocated; 3.12 MiB free; 454.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:21:47,050 controller 1396628 deployment_state.py:674 - Exception in Replica(id='xsjoeks6', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1398104, ip=10.130.253.103, actor_id=be7b3bdd326e00eddb810edc01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f6034275700>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 541.87 MiB already allocated; 3.12 MiB free; 542.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:21:47,052 controller 1396628 deployment_state.py:674 - Exception in Replica(id='xgm1pyx4', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1398105, ip=10.130.253.103, actor_id=a900f4c9508a352e5fd7556901000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f3004235790>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 385.70 MiB already allocated; 3.12 MiB free; 386.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:21:47,053 controller 1396628 deployment_state.py:674 - Exception in Replica(id='y0kicax0', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1398108, ip=10.130.253.103, actor_id=d98c34afd7c2884f136e04d701000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fd23ee017c0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 313.62 MiB already allocated; 3.12 MiB free; 314.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:21:47,059 controller 1396628 deployment_state.py:2228 - Replica(id='kag25vjz', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398092)[0m 2024-08-28 15:21:42.545386400 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398092)[0m 2024-08-28 15:21:42.545437886 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 7x across cluster][0m
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:21:47,060 controller 1396628 deployment_state.py:2228 - Replica(id='4ixbl0cs', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:21:47,061 controller 1396628 deployment_state.py:2228 - Replica(id='z0mk9srm', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:21:47,062 controller 1396628 deployment_state.py:2228 - Replica(id='xsjoeks6', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:21:47,064 controller 1396628 deployment_state.py:2228 - Replica(id='xgm1pyx4', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:21:47,065 controller 1396628 deployment_state.py:2228 - Replica(id='y0kicax0', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:21:47,070 controller 1396628 deployment_state.py:1910 - Adding 6 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:21:47,340 controller 1396628 deployment_state.py:674 - Exception in Replica(id='2npuuwbl', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1398098, ip=10.130.253.103, actor_id=7a0c1d262cce76a9b89fb78301000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f0c3ad096d0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 29, in load
[36m(ServeController pid=1396628)[0m     self.llm.to(self.device).eval()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1145, in to
[36m(ServeController pid=1396628)[0m     return self._apply(convert)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 797, in _apply
[36m(ServeController pid=1396628)[0m     module._apply(fn)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 820, in _apply
[36m(ServeController pid=1396628)[0m     param_applied = fn(param)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1143, in convert
[36m(ServeController pid=1396628)[0m     return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 1.14 GiB already allocated; 3.12 MiB free; 1.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:21:47,351 controller 1396628 deployment_state.py:2228 - Replica(id='2npuuwbl', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:21:47,359 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:21:47,474 controller 1396628 deployment_state.py:674 - Exception in Replica(id='k4p2r8xv', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1398093, ip=10.130.253.103, actor_id=ece3324bb44f7841e2e6fdb701000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f86180b5790>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 29, in load
[36m(ServeController pid=1396628)[0m     self.llm.to(self.device).eval()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1145, in to
[36m(ServeController pid=1396628)[0m     return self._apply(convert)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 797, in _apply
[36m(ServeController pid=1396628)[0m     module._apply(fn)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 820, in _apply
[36m(ServeController pid=1396628)[0m     param_applied = fn(param)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1143, in convert
[36m(ServeController pid=1396628)[0m     return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 1.14 GiB already allocated; 3.12 MiB free; 1.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:21:47,481 controller 1396628 deployment_state.py:2228 - Replica(id='k4p2r8xv', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:21:47,486 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:21:51,073 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398108)[0m 2024-08-28 15:21:43,600 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398108)[0m [2024-08-28 15:21:43,600-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1398108] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398108)[0m 2024-08-28 15:21:43,600 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398108)[0m [2024-08-28 15:21:43,600-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1398108]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398108)[0m 2024-08-28 15:21:43,600 WETEXT INFO skip building fst for zh_normalizer ...[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398108)[0m [2024-08-28 15:21:43,600-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1398108] skip building fst for zh_normalizer ...[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398092)[0m 2024-08-28 15:21:44,593 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398092)[0m [2024-08-28 15:21:44,593-wetext-en_normalizer-processor.py-build_fst-95-INFO-1398092] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398092)[0m 2024-08-28 15:21:44,594 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398092)[0m [2024-08-28 15:21:44,594-wetext-en_normalizer-processor.py-build_fst-96-INFO-1398092]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398092)[0m 2024-08-28 15:21:44,594 WETEXT INFO skip building fst for en_normalizer ...[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1398092)[0m [2024-08-28 15:21:44,594-wetext-en_normalizer-processor.py-build_fst-97-INFO-1398092] skip building fst for en_normalizer ...[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401641)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401641)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401643)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401643)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401697)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401697)[0m   warnings.warn([32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401643)[0m [2024-08-28 15:22:03,184-root-flow.py-__init__-45-INFO-1401643] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401643)[0m 2024-08-28 15:22:07.555321512 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401643)[0m 2024-08-28 15:22:07.555368970 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401697)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401697)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401697)[0m [2024-08-28 15:22:03,940-root-flow.py-__init__-45-INFO-1401697] input frame rate=50[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401643)[0m 2024-08-28 15:22:08,530 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401643)[0m [2024-08-28 15:22:08,530-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1401643] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401643)[0m 2024-08-28 15:22:08,530 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401643)[0m [2024-08-28 15:22:08,530-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1401643]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401643)[0m 2024-08-28 15:22:08,530 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401643)[0m [2024-08-28 15:22:08,530-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1401643] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401643)[0m 2024-08-28 15:22:09,478 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401643)[0m [2024-08-28 15:22:09,478-wetext-en_normalizer-processor.py-build_fst-95-INFO-1401643] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401643)[0m 2024-08-28 15:22:09,479 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401643)[0m [2024-08-28 15:22:09,479-wetext-en_normalizer-processor.py-build_fst-96-INFO-1401643]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401643)[0m 2024-08-28 15:22:09,479 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401643)[0m [2024-08-28 15:22:09,479-wetext-en_normalizer-processor.py-build_fst-97-INFO-1401643] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:22:13,206 controller 1396628 deployment_state.py:674 - Exception in Replica(id='7sjahhx1', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1401642, ip=10.130.253.103, actor_id=8674fedf9cc09cb74fbdb95101000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f7f101747c0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 609.95 MiB already allocated; 3.12 MiB free; 610.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:22:13,208 controller 1396628 deployment_state.py:674 - Exception in Replica(id='cfrhc02t', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1401644, ip=10.130.253.103, actor_id=6cf11a2970ea2a3f05b771a001000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fc6901747c0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 385.70 MiB already allocated; 3.12 MiB free; 386.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:22:13,210 controller 1396628 deployment_state.py:674 - Exception in Replica(id='0ox5zvct', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1401645, ip=10.130.253.103, actor_id=7e472f64557a2ed45422ef5501000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f57280b56a0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 854.22 MiB already allocated; 3.12 MiB free; 856.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:22:13,212 controller 1396628 deployment_state.py:674 - Exception in Replica(id='190du5ae', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1401648, ip=10.130.253.103, actor_id=872055b5c5cfbd405bfaddc401000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f096c6ae700>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 385.70 MiB already allocated; 3.12 MiB free; 386.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:22:13,214 controller 1396628 deployment_state.py:674 - Exception in Replica(id='2lpojfwu', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1401683, ip=10.130.253.103, actor_id=9510ee12d3b33538c467f24f01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fe2bc735760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 89.35 MiB already allocated; 3.12 MiB free; 90.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:22:13,216 controller 1396628 deployment_state.py:674 - Exception in Replica(id='8pkqdmxl', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1401697, ip=10.130.253.103, actor_id=5d57edd550e3ed96b9e909c001000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f7b547b5700>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 922.30 MiB already allocated; 3.12 MiB free; 924.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:22:13,220 controller 1396628 deployment_state.py:2228 - Replica(id='7sjahhx1', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:22:13,220 controller 1396628 deployment_state.py:2228 - Replica(id='cfrhc02t', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:22:13,221 controller 1396628 deployment_state.py:2228 - Replica(id='0ox5zvct', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:22:13,222 controller 1396628 deployment_state.py:2228 - Replica(id='190du5ae', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:22:13,223 controller 1396628 deployment_state.py:2228 - Replica(id='2lpojfwu', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:22:13,224 controller 1396628 deployment_state.py:2228 - Replica(id='8pkqdmxl', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:22:13,228 controller 1396628 deployment_state.py:1910 - Adding 6 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401644)[0m 2024-08-28 15:22:08.675380269 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401644)[0m 2024-08-28 15:22:08.675431792 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 7x across cluster][0m
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:22:13,623 controller 1396628 deployment_state.py:674 - Exception in Replica(id='o9idb7uw', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1401643, ip=10.130.253.103, actor_id=90c128b3b5bbf3d42f92216f01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fa334235790>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 29, in load
[36m(ServeController pid=1396628)[0m     self.llm.to(self.device).eval()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1145, in to
[36m(ServeController pid=1396628)[0m     return self._apply(convert)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 797, in _apply
[36m(ServeController pid=1396628)[0m     module._apply(fn)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 820, in _apply
[36m(ServeController pid=1396628)[0m     param_applied = fn(param)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1143, in convert
[36m(ServeController pid=1396628)[0m     return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 1.14 GiB already allocated; 3.12 MiB free; 1.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:22:13,629 controller 1396628 deployment_state.py:2228 - Replica(id='o9idb7uw', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:22:13,633 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401683)[0m 2024-08-28 15:22:09,505 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401683)[0m [2024-08-28 15:22:09,505-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1401683] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401683)[0m 2024-08-28 15:22:09,505 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401683)[0m [2024-08-28 15:22:09,505-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1401683]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401683)[0m 2024-08-28 15:22:09,505 WETEXT INFO skip building fst for zh_normalizer ...[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401683)[0m [2024-08-28 15:22:09,505-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1401683] skip building fst for zh_normalizer ...[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403968)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403968)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401683)[0m 2024-08-28 15:22:10,577 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401683)[0m [2024-08-28 15:22:10,577-wetext-en_normalizer-processor.py-build_fst-95-INFO-1401683] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401683)[0m 2024-08-28 15:22:10,578 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401683)[0m [2024-08-28 15:22:10,578-wetext-en_normalizer-processor.py-build_fst-96-INFO-1401683]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401683)[0m 2024-08-28 15:22:10,578 WETEXT INFO skip building fst for en_normalizer ...[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401683)[0m [2024-08-28 15:22:10,578-wetext-en_normalizer-processor.py-build_fst-97-INFO-1401683] skip building fst for en_normalizer ...[32m [repeated 7x across cluster][0m
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:22:21,126 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403968)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403968)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1404009)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1404009)[0m   warnings.warn([32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403968)[0m [2024-08-28 15:22:29,326-root-flow.py-__init__-45-INFO-1403968] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403969)[0m 2024-08-28 15:22:33.751139509 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403969)[0m 2024-08-28 15:22:33.751178672 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1404009)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1404009)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403968)[0m 2024-08-28 15:22:34,549 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403968)[0m [2024-08-28 15:22:34,549-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1403968] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403968)[0m 2024-08-28 15:22:34,550 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403968)[0m [2024-08-28 15:22:34,550-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1403968]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403968)[0m 2024-08-28 15:22:34,550 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403968)[0m [2024-08-28 15:22:34,550-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1403968] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403970)[0m [2024-08-28 15:22:29,832-root-flow.py-__init__-45-INFO-1403970] input frame rate=50[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403968)[0m 2024-08-28 15:22:35,477 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403968)[0m [2024-08-28 15:22:35,477-wetext-en_normalizer-processor.py-build_fst-95-INFO-1403968] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403968)[0m 2024-08-28 15:22:35,477 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403968)[0m [2024-08-28 15:22:35,477-wetext-en_normalizer-processor.py-build_fst-96-INFO-1403968]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403968)[0m 2024-08-28 15:22:35,477 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403968)[0m [2024-08-28 15:22:35,477-wetext-en_normalizer-processor.py-build_fst-97-INFO-1403968] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:22:37,959 controller 1396628 deployment_state.py:674 - Exception in Replica(id='cjz9py4w', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1403967, ip=10.130.253.103, actor_id=34c6df73ce77090e567dca6101000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7feb580b5730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 21.28 MiB already allocated; 13.12 MiB free; 22.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:22:37,961 controller 1396628 deployment_state.py:674 - Exception in Replica(id='aorma1pt', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1403969, ip=10.130.253.103, actor_id=292d09f3f786af6fbb220b4a01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fd094735730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 645.99 MiB already allocated; 13.12 MiB free; 646.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:22:37,962 controller 1396628 deployment_state.py:674 - Exception in Replica(id='vsymadc6', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1403970, ip=10.130.253.103, actor_id=285d1fad3580ca1c1f28d40f01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fef5c17d7c0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 105.38 MiB already allocated; 13.12 MiB free; 106.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:22:37,964 controller 1396628 deployment_state.py:674 - Exception in Replica(id='btf1q2iy', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1403971, ip=10.130.253.103, actor_id=b53744e987f1202196b0d35501000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f7820735700>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 489.81 MiB already allocated; 13.12 MiB free; 490.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:22:37,965 controller 1396628 deployment_state.py:674 - Exception in Replica(id='03wuo001', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1403972, ip=10.130.253.103, actor_id=a4d4a4dfb711743232b4937201000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f4a5c075760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 818.18 MiB already allocated; 13.12 MiB free; 820.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:22:37,967 controller 1396628 deployment_state.py:674 - Exception in Replica(id='amd29ey3', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1404009, ip=10.130.253.103, actor_id=dffe77102f1a5f7c9f7846aa01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fed7c075700>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 541.87 MiB already allocated; 13.12 MiB free; 542.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:22:37,969 controller 1396628 deployment_state.py:2228 - Replica(id='cjz9py4w', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:22:37,969 controller 1396628 deployment_state.py:2228 - Replica(id='aorma1pt', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:22:37,970 controller 1396628 deployment_state.py:2228 - Replica(id='vsymadc6', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:22:37,970 controller 1396628 deployment_state.py:2228 - Replica(id='btf1q2iy', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:22:37,971 controller 1396628 deployment_state.py:2228 - Replica(id='03wuo001', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:22:37,972 controller 1396628 deployment_state.py:2228 - Replica(id='amd29ey3', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:22:37,977 controller 1396628 deployment_state.py:1910 - Adding 6 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:22:38,118 controller 1396628 deployment_state.py:674 - Exception in Replica(id='aciyc43o', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1403968, ip=10.130.253.103, actor_id=9d5cea5a4d7b371c847455b701000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f83a47f57c0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 818.18 MiB already allocated; 13.12 MiB free; 820.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:22:38,125 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:22:38,247 controller 1396628 deployment_state.py:2228 - Replica(id='aciyc43o', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405901)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405901)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403970)[0m 2024-08-28 15:22:34.394387952 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403970)[0m 2024-08-28 15:22:34.394436486 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403970)[0m 2024-08-28 15:22:35,179 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403970)[0m [2024-08-28 15:22:35,179-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1403970] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403970)[0m 2024-08-28 15:22:35,179 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403970)[0m [2024-08-28 15:22:35,179-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1403970]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403970)[0m 2024-08-28 15:22:35,179 WETEXT INFO skip building fst for zh_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403970)[0m [2024-08-28 15:22:35,179-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1403970] skip building fst for zh_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403970)[0m 2024-08-28 15:22:36,108 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403970)[0m [2024-08-28 15:22:36,108-wetext-en_normalizer-processor.py-build_fst-95-INFO-1403970] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403970)[0m 2024-08-28 15:22:36,108 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403970)[0m [2024-08-28 15:22:36,108-wetext-en_normalizer-processor.py-build_fst-96-INFO-1403970]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403970)[0m 2024-08-28 15:22:36,108 WETEXT INFO skip building fst for en_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1403970)[0m [2024-08-28 15:22:36,108-wetext-en_normalizer-processor.py-build_fst-97-INFO-1403970] skip building fst for en_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:22:51,161 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405918)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405918)[0m   warnings.warn([32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405901)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405901)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405897)[0m [2024-08-28 15:22:54,138-root-flow.py-__init__-45-INFO-1405897] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405896)[0m 2024-08-28 15:22:58.516658636 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405896)[0m 2024-08-28 15:22:58.516700176 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405898)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405898)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405896)[0m 2024-08-28 15:22:59,285 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405896)[0m [2024-08-28 15:22:59,285-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1405896] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405896)[0m 2024-08-28 15:22:59,285 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405896)[0m [2024-08-28 15:22:59,285-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1405896]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405896)[0m 2024-08-28 15:22:59,286 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405896)[0m [2024-08-28 15:22:59,286-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1405896] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405898)[0m [2024-08-28 15:22:54,726-root-flow.py-__init__-45-INFO-1405898] input frame rate=50[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405901)[0m 2024-08-28 15:23:00,181 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405901)[0m [2024-08-28 15:23:00,181-wetext-en_normalizer-processor.py-build_fst-95-INFO-1405901] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405901)[0m 2024-08-28 15:23:00,181 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405901)[0m [2024-08-28 15:23:00,181-wetext-en_normalizer-processor.py-build_fst-96-INFO-1405901]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405901)[0m 2024-08-28 15:23:00,181 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405901)[0m [2024-08-28 15:23:00,181-wetext-en_normalizer-processor.py-build_fst-97-INFO-1405901] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:23:02,949 controller 1396628 deployment_state.py:674 - Exception in Replica(id='bowzyj4w', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1405896, ip=10.130.253.103, actor_id=cc263e83891a4d39a061ceec01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f47187b5700>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 521.86 MiB already allocated; 13.12 MiB free; 522.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:23:02,951 controller 1396628 deployment_state.py:674 - Exception in Replica(id='ylysn5kd', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1405897, ip=10.130.253.103, actor_id=b34208016bc0cf7af147028501000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f26b87b5700>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 609.95 MiB already allocated; 13.12 MiB free; 610.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:23:02,952 controller 1396628 deployment_state.py:674 - Exception in Replica(id='ud638a02', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1405898, ip=10.130.253.103, actor_id=6373ea137f6b52adbeb7aeea01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fdf240b56d0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 229.51 MiB already allocated; 13.12 MiB free; 230.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:23:02,953 controller 1396628 deployment_state.py:674 - Exception in Replica(id='72a0qn88', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1405899, ip=10.130.253.103, actor_id=29ecf0645a0aebe765a26e3a01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fb9b4275790>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 750.11 MiB already allocated; 13.12 MiB free; 752.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:23:02,955 controller 1396628 deployment_state.py:674 - Exception in Replica(id='3xjb4zik', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1405901, ip=10.130.253.103, actor_id=c3524f9ef92cee4be6169e7d01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fde286ad7c0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 1.00 GiB already allocated; 13.12 MiB free; 1.00 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:23:02,956 controller 1396628 deployment_state.py:674 - Exception in Replica(id='fmahpsze', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1405918, ip=10.130.253.103, actor_id=2fa31fc3a1dcf1e7dbda19c701000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f68a46ad760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 245.53 MiB already allocated; 13.12 MiB free; 246.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:02,958 controller 1396628 deployment_state.py:2228 - Replica(id='bowzyj4w', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:02,958 controller 1396628 deployment_state.py:2228 - Replica(id='ylysn5kd', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:02,959 controller 1396628 deployment_state.py:2228 - Replica(id='ud638a02', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:02,959 controller 1396628 deployment_state.py:2228 - Replica(id='72a0qn88', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:02,960 controller 1396628 deployment_state.py:2228 - Replica(id='3xjb4zik', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:02,961 controller 1396628 deployment_state.py:2228 - Replica(id='fmahpsze', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:02,964 controller 1396628 deployment_state.py:1910 - Adding 6 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:23:03,109 controller 1396628 deployment_state.py:674 - Exception in Replica(id='hcl0aafk', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1405900, ip=10.130.253.103, actor_id=8a52a575f7b2c3d5bc30376501000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f1780735700>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 1.26 MiB already allocated; 13.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:03,117 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:03,239 controller 1396628 deployment_state.py:2228 - Replica(id='hcl0aafk', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407856)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407856)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405918)[0m 2024-08-28 15:22:58.975352088 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405918)[0m 2024-08-28 15:22:58.975394719 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405898)[0m 2024-08-28 15:22:59,797 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405898)[0m [2024-08-28 15:22:59,797-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1405898] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405898)[0m 2024-08-28 15:22:59,797 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405898)[0m [2024-08-28 15:22:59,797-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1405898]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405898)[0m 2024-08-28 15:22:59,797 WETEXT INFO skip building fst for zh_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405898)[0m [2024-08-28 15:22:59,797-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1405898] skip building fst for zh_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405898)[0m 2024-08-28 15:23:00,751 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405898)[0m [2024-08-28 15:23:00,751-wetext-en_normalizer-processor.py-build_fst-95-INFO-1405898] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405898)[0m 2024-08-28 15:23:00,751 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405898)[0m [2024-08-28 15:23:00,751-wetext-en_normalizer-processor.py-build_fst-96-INFO-1405898]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405898)[0m 2024-08-28 15:23:00,751 WETEXT INFO skip building fst for en_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1405898)[0m [2024-08-28 15:23:00,751-wetext-en_normalizer-processor.py-build_fst-97-INFO-1405898] skip building fst for en_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407859)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407859)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407874)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407874)[0m   warnings.warn([32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407856)[0m [2024-08-28 15:23:18,784-root-flow.py-__init__-45-INFO-1407856] input frame rate=50
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:23:21,188 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407874)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407874)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407859)[0m 2024-08-28 15:23:23.669111324 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407859)[0m 2024-08-28 15:23:23.669154128 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407874)[0m [2024-08-28 15:23:19,530-root-flow.py-__init__-45-INFO-1407874] input frame rate=50[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407859)[0m 2024-08-28 15:23:24,496 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407859)[0m [2024-08-28 15:23:24,496-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1407859] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407859)[0m 2024-08-28 15:23:24,496 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407859)[0m [2024-08-28 15:23:24,496-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1407859]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407859)[0m 2024-08-28 15:23:24,496 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407859)[0m [2024-08-28 15:23:24,496-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1407859] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407859)[0m 2024-08-28 15:23:25,437 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407859)[0m [2024-08-28 15:23:25,437-wetext-en_normalizer-processor.py-build_fst-95-INFO-1407859] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407859)[0m 2024-08-28 15:23:25,437 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407859)[0m [2024-08-28 15:23:25,437-wetext-en_normalizer-processor.py-build_fst-96-INFO-1407859]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407859)[0m 2024-08-28 15:23:25,437 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407859)[0m [2024-08-28 15:23:25,437-wetext-en_normalizer-processor.py-build_fst-97-INFO-1407859] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:23:27,978 controller 1396628 deployment_state.py:674 - Exception in Replica(id='g85y17os', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1407856, ip=10.130.253.103, actor_id=73e078bfdfdd5553e7437e8601000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fe4a43bc6a0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 645.99 MiB already allocated; 1.12 MiB free; 646.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:23:27,981 controller 1396628 deployment_state.py:674 - Exception in Replica(id='pwmzouxn', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1407858, ip=10.130.253.103, actor_id=4eb02ff6ff5f9605fdf0f48101000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f7d1037c730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 401.71 MiB already allocated; 1.12 MiB free; 402.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:23:27,983 controller 1396628 deployment_state.py:674 - Exception in Replica(id='hrufl4of', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1407861, ip=10.130.253.103, actor_id=f4081e7e79d74ee97a3eac1401000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f4b481f5730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 698.05 MiB already allocated; 1.12 MiB free; 700.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:23:27,984 controller 1396628 deployment_state.py:674 - Exception in Replica(id='ulbv5k4z', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1407862, ip=10.130.253.103, actor_id=74908d610330ab4ff1d2b64a01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fccb072e730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 73.34 MiB already allocated; 1.12 MiB free; 74.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:23:27,985 controller 1396628 deployment_state.py:674 - Exception in Replica(id='dqu807yb', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1407874, ip=10.130.253.103, actor_id=73a6d1f8e622cf072b09e0b001000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f0284b44700>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 489.81 MiB already allocated; 1.12 MiB free; 490.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:27,987 controller 1396628 deployment_state.py:2228 - Replica(id='g85y17os', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:27,987 controller 1396628 deployment_state.py:2228 - Replica(id='pwmzouxn', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:27,988 controller 1396628 deployment_state.py:2228 - Replica(id='hrufl4of', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:27,989 controller 1396628 deployment_state.py:2228 - Replica(id='ulbv5k4z', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:27,989 controller 1396628 deployment_state.py:2228 - Replica(id='dqu807yb', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:27,993 controller 1396628 deployment_state.py:1910 - Adding 5 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:23:28,128 controller 1396628 deployment_state.py:674 - Exception in Replica(id='5olgbe06', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1407859, ip=10.130.253.103, actor_id=32c8879ff74b7ea3f333454e01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fd6a00b56a0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 1010.40 MiB already allocated; 1.12 MiB free; 1012.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:23:28,130 controller 1396628 deployment_state.py:674 - Exception in Replica(id='eeheofl6', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1407860, ip=10.130.253.103, actor_id=83593fc140bcff20b8e8c3ef01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f42507b5730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 125.40 MiB already allocated; 1.12 MiB free; 126.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:28,133 controller 1396628 deployment_state.py:2228 - Replica(id='5olgbe06', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:28,134 controller 1396628 deployment_state.py:2228 - Replica(id='eeheofl6', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:28,138 controller 1396628 deployment_state.py:1910 - Adding 2 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409813)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409813)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407860)[0m 2024-08-28 15:23:24.223878510 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407860)[0m 2024-08-28 15:23:24.223924014 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407862)[0m 2024-08-28 15:23:25,278 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407862)[0m [2024-08-28 15:23:25,278-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1407862] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407862)[0m 2024-08-28 15:23:25,278 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407862)[0m [2024-08-28 15:23:25,278-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1407862]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407862)[0m 2024-08-28 15:23:25,279 WETEXT INFO skip building fst for zh_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407862)[0m [2024-08-28 15:23:25,279-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1407862] skip building fst for zh_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407862)[0m 2024-08-28 15:23:26,209 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407862)[0m [2024-08-28 15:23:26,209-wetext-en_normalizer-processor.py-build_fst-95-INFO-1407862] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407862)[0m 2024-08-28 15:23:26,209 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407862)[0m [2024-08-28 15:23:26,209-wetext-en_normalizer-processor.py-build_fst-96-INFO-1407862]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407862)[0m 2024-08-28 15:23:26,209 WETEXT INFO skip building fst for en_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1407862)[0m [2024-08-28 15:23:26,209-wetext-en_normalizer-processor.py-build_fst-97-INFO-1407862] skip building fst for en_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409813)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409813)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409822)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409822)[0m   warnings.warn([32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409813)[0m [2024-08-28 15:23:44,298-root-flow.py-__init__-45-INFO-1409813] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409813)[0m 2024-08-28 15:23:48.421564009 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409813)[0m 2024-08-28 15:23:48.421607611 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409815)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409815)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409813)[0m 2024-08-28 15:23:49,349 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409813)[0m [2024-08-28 15:23:49,349-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1409813] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409813)[0m 2024-08-28 15:23:49,349 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409813)[0m [2024-08-28 15:23:49,349-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1409813]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409813)[0m 2024-08-28 15:23:49,349 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409813)[0m [2024-08-28 15:23:49,349-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1409813] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409815)[0m [2024-08-28 15:23:44,786-root-flow.py-__init__-45-INFO-1409815] input frame rate=50[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409813)[0m 2024-08-28 15:23:50,280 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409813)[0m [2024-08-28 15:23:50,280-wetext-en_normalizer-processor.py-build_fst-95-INFO-1409813] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409813)[0m 2024-08-28 15:23:50,280 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409813)[0m [2024-08-28 15:23:50,280-wetext-en_normalizer-processor.py-build_fst-96-INFO-1409813]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409813)[0m 2024-08-28 15:23:50,280 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409813)[0m [2024-08-28 15:23:50,280-wetext-en_normalizer-processor.py-build_fst-97-INFO-1409813] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:23:51,216 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:23:53,069 controller 1396628 deployment_state.py:674 - Exception in Replica(id='wgke8395', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1409823, ip=10.130.253.103, actor_id=db865c9c5f86bd9fc0e7a1b801000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f6f7437c730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 385.70 MiB already allocated; 11.12 MiB free; 386.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:53,076 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:23:53,195 controller 1396628 deployment_state.py:674 - Exception in Replica(id='owjdb2oh', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1409812, ip=10.130.253.103, actor_id=3c6e277ab544efd12f5e8c1101000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f886072e6d0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 714.06 MiB already allocated; 11.12 MiB free; 716.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:23:53,197 controller 1396628 deployment_state.py:674 - Exception in Replica(id='4wv4zdx5', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1409813, ip=10.130.253.103, actor_id=29b0381fd48651b5aeb1d14301000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f43906ae760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 750.11 MiB already allocated; 11.12 MiB free; 752.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:23:53,199 controller 1396628 deployment_state.py:674 - Exception in Replica(id='qqwggukj', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1409814, ip=10.130.253.103, actor_id=a575004822a1f0fcfe258e3601000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f36482b5790>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 593.93 MiB already allocated; 11.12 MiB free; 594.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:23:53,200 controller 1396628 deployment_state.py:674 - Exception in Replica(id='irqhqr00', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1409815, ip=10.130.253.103, actor_id=6575b2b44002d0c1bad334ea01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f54680b5730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 349.65 MiB already allocated; 11.12 MiB free; 350.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:23:53,202 controller 1396628 deployment_state.py:674 - Exception in Replica(id='uu6netak', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1409816, ip=10.130.253.103, actor_id=31567ad1cb34aca6f6657d2401000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fdde4775760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 105.38 MiB already allocated; 11.12 MiB free; 106.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:23:53,204 controller 1396628 deployment_state.py:674 - Exception in Replica(id='c66o0hqw', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1409822, ip=10.130.253.103, actor_id=5f04b451e2d0ec8d6e964feb01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fd06e7f9790>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 541.87 MiB already allocated; 11.12 MiB free; 542.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:53,206 controller 1396628 deployment_state.py:2228 - Replica(id='wgke8395', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:53,206 controller 1396628 deployment_state.py:2228 - Replica(id='owjdb2oh', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:53,207 controller 1396628 deployment_state.py:2228 - Replica(id='4wv4zdx5', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:53,208 controller 1396628 deployment_state.py:2228 - Replica(id='qqwggukj', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:53,209 controller 1396628 deployment_state.py:2228 - Replica(id='irqhqr00', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:53,209 controller 1396628 deployment_state.py:2228 - Replica(id='uu6netak', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:53,210 controller 1396628 deployment_state.py:2228 - Replica(id='c66o0hqw', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:23:53,214 controller 1396628 deployment_state.py:1910 - Adding 6 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411793)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411793)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409823)[0m 2024-08-28 15:23:49.046245702 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409823)[0m 2024-08-28 15:23:49.046292640 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409816)[0m 2024-08-28 15:23:49,898 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409816)[0m [2024-08-28 15:23:49,898-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1409816] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409816)[0m 2024-08-28 15:23:49,899 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409816)[0m [2024-08-28 15:23:49,899-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1409816]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409816)[0m 2024-08-28 15:23:49,899 WETEXT INFO skip building fst for zh_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409816)[0m [2024-08-28 15:23:49,899-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1409816] skip building fst for zh_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409816)[0m 2024-08-28 15:23:50,852 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409816)[0m [2024-08-28 15:23:50,852-wetext-en_normalizer-processor.py-build_fst-95-INFO-1409816] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409816)[0m 2024-08-28 15:23:50,852 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409816)[0m [2024-08-28 15:23:50,852-wetext-en_normalizer-processor.py-build_fst-96-INFO-1409816]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409816)[0m 2024-08-28 15:23:50,853 WETEXT INFO skip building fst for en_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1409816)[0m [2024-08-28 15:23:50,853-wetext-en_normalizer-processor.py-build_fst-97-INFO-1409816] skip building fst for en_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411798)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411798)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411796)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411796)[0m   warnings.warn([32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411798)[0m [2024-08-28 15:24:09,234-root-flow.py-__init__-45-INFO-1411798] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411798)[0m 2024-08-28 15:24:13.944466858 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411798)[0m 2024-08-28 15:24:13.944514164 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411794)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411794)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411794)[0m [2024-08-28 15:24:09,650-root-flow.py-__init__-45-INFO-1411794] input frame rate=50[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411798)[0m 2024-08-28 15:24:14,788 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411798)[0m [2024-08-28 15:24:14,788-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1411798] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411798)[0m 2024-08-28 15:24:14,789 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411798)[0m [2024-08-28 15:24:14,789-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1411798]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411798)[0m 2024-08-28 15:24:14,789 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411798)[0m [2024-08-28 15:24:14,789-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1411798] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411798)[0m 2024-08-28 15:24:15,709 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411798)[0m [2024-08-28 15:24:15,709-wetext-en_normalizer-processor.py-build_fst-95-INFO-1411798] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411798)[0m 2024-08-28 15:24:15,709 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411798)[0m [2024-08-28 15:24:15,709-wetext-en_normalizer-processor.py-build_fst-96-INFO-1411798]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411798)[0m 2024-08-28 15:24:15,709 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411798)[0m [2024-08-28 15:24:15,709-wetext-en_normalizer-processor.py-build_fst-97-INFO-1411798] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:24:19,167 controller 1396628 deployment_state.py:674 - Exception in Replica(id='wb70yj0w', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1411792, ip=10.130.253.103, actor_id=68e9247e2d019dfb2048a60d01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f74a072e730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 31.74 GiB total capacity; 1.02 GiB already allocated; 9.12 MiB free; 1.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:24:19,169 controller 1396628 deployment_state.py:674 - Exception in Replica(id='b2394gy0', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1411793, ip=10.130.253.103, actor_id=9f2a1176f933ebff759e85e601000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fea88b04730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 229.51 MiB already allocated; 9.12 MiB free; 230.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:24:19,171 controller 1396628 deployment_state.py:674 - Exception in Replica(id='gtbu6l8y', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1411794, ip=10.130.253.103, actor_id=e1240f011f536cbf4973f5a501000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fc1986ee760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 1.26 MiB already allocated; 9.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:24:19,172 controller 1396628 deployment_state.py:674 - Exception in Replica(id='uc453jl1', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1411795, ip=10.130.253.103, actor_id=6092f936eafb68535468742201000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f2c1893f730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 281.57 MiB already allocated; 9.12 MiB free; 282.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:24:19,174 controller 1396628 deployment_state.py:674 - Exception in Replica(id='ly36lpmp', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1411796, ip=10.130.253.103, actor_id=af75434ab91cd0f2bcf5bb0801000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fbafc1756d0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 385.70 MiB already allocated; 9.12 MiB free; 386.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:24:19,175 controller 1396628 deployment_state.py:674 - Exception in Replica(id='jvsgxs5a', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1411797, ip=10.130.253.103, actor_id=6283e3bf6bb6a77afd15646b01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fb0543bc730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 297.59 MiB already allocated; 9.12 MiB free; 298.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:24:19,177 controller 1396628 deployment_state.py:2228 - Replica(id='wb70yj0w', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:24:19,178 controller 1396628 deployment_state.py:2228 - Replica(id='b2394gy0', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:24:19,179 controller 1396628 deployment_state.py:2228 - Replica(id='gtbu6l8y', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:24:19,179 controller 1396628 deployment_state.py:2228 - Replica(id='uc453jl1', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:24:19,181 controller 1396628 deployment_state.py:2228 - Replica(id='ly36lpmp', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:24:19,182 controller 1396628 deployment_state.py:2228 - Replica(id='jvsgxs5a', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:24:19,186 controller 1396628 deployment_state.py:1910 - Adding 6 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411794)[0m 2024-08-28 15:24:14.907860232 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411794)[0m 2024-08-28 15:24:14.907907414 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 6x across cluster][0m
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:24:19,331 controller 1396628 deployment_state.py:674 - Exception in Replica(id='qjoaxf51', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1411798, ip=10.130.253.103, actor_id=bd85518a0b055bd67c24d91401000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fba882b56d0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 29, in load
[36m(ServeController pid=1396628)[0m     self.llm.to(self.device).eval()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1145, in to
[36m(ServeController pid=1396628)[0m     return self._apply(convert)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 797, in _apply
[36m(ServeController pid=1396628)[0m     module._apply(fn)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 820, in _apply
[36m(ServeController pid=1396628)[0m     param_applied = fn(param)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1143, in convert
[36m(ServeController pid=1396628)[0m     return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 1.14 GiB already allocated; 9.12 MiB free; 1.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:24:19,341 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:24:19,468 controller 1396628 deployment_state.py:2228 - Replica(id='qjoaxf51', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:24:21,254 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411796)[0m 2024-08-28 15:24:15,855 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411796)[0m [2024-08-28 15:24:15,855-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1411796] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411796)[0m 2024-08-28 15:24:15,856 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411796)[0m [2024-08-28 15:24:15,856-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1411796]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411796)[0m 2024-08-28 15:24:15,856 WETEXT INFO skip building fst for zh_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411796)[0m [2024-08-28 15:24:15,856-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1411796] skip building fst for zh_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411794)[0m 2024-08-28 15:24:16,976 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411794)[0m [2024-08-28 15:24:16,976-wetext-en_normalizer-processor.py-build_fst-95-INFO-1411794] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411794)[0m 2024-08-28 15:24:16,976 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411794)[0m [2024-08-28 15:24:16,976-wetext-en_normalizer-processor.py-build_fst-96-INFO-1411794]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411794)[0m 2024-08-28 15:24:16,976 WETEXT INFO skip building fst for en_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1411794)[0m [2024-08-28 15:24:16,976-wetext-en_normalizer-processor.py-build_fst-97-INFO-1411794] skip building fst for en_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413865)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413865)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413865)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413865)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413903)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413903)[0m   warnings.warn([32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413869)[0m [2024-08-28 15:24:35,534-root-flow.py-__init__-45-INFO-1413869] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413864)[0m 2024-08-28 15:24:39.917931274 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413864)[0m 2024-08-28 15:24:39.917971386 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413872)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413872)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413864)[0m 2024-08-28 15:24:40,723 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413864)[0m [2024-08-28 15:24:40,723-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1413864] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413864)[0m 2024-08-28 15:24:40,723 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413864)[0m [2024-08-28 15:24:40,723-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1413864]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413864)[0m 2024-08-28 15:24:40,723 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413864)[0m [2024-08-28 15:24:40,723-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1413864] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413872)[0m [2024-08-28 15:24:36,018-root-flow.py-__init__-45-INFO-1413872] input frame rate=50[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413864)[0m 2024-08-28 15:24:41,900 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413864)[0m [2024-08-28 15:24:41,900-wetext-en_normalizer-processor.py-build_fst-95-INFO-1413864] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413864)[0m 2024-08-28 15:24:41,901 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413864)[0m [2024-08-28 15:24:41,901-wetext-en_normalizer-processor.py-build_fst-96-INFO-1413864]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413864)[0m 2024-08-28 15:24:41,901 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413864)[0m [2024-08-28 15:24:41,901-wetext-en_normalizer-processor.py-build_fst-97-INFO-1413864] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:24:44,339 controller 1396628 deployment_state.py:674 - Exception in Replica(id='rv88dzo1', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1413864, ip=10.130.253.103, actor_id=5f5880f4089f5b890531d87101000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fbd64775730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 802.17 MiB already allocated; 15.12 MiB free; 804.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:24:44,342 controller 1396628 deployment_state.py:674 - Exception in Replica(id='5bvsm66u', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1413865, ip=10.130.253.103, actor_id=f2291cd8d5d7cf95b1f51bd601000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f922c1347c0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 453.77 MiB already allocated; 15.12 MiB free; 454.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:24:44,344 controller 1396628 deployment_state.py:674 - Exception in Replica(id='b28gqzvj', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1413869, ip=10.130.253.103, actor_id=5f3be77c0ed09f8b26ac04d601000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f2488735730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 125.40 MiB already allocated; 15.12 MiB free; 126.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:24:44,346 controller 1396628 deployment_state.py:674 - Exception in Replica(id='xl43e2o0', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1413872, ip=10.130.253.103, actor_id=1354173932234fc6b32e337c01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f87a47f5730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 593.93 MiB already allocated; 15.12 MiB free; 594.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:24:44,348 controller 1396628 deployment_state.py:674 - Exception in Replica(id='eg1l28ap', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1413874, ip=10.130.253.103, actor_id=432bf9d165b8c46570d5fb1b01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f06786ae6d0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 609.95 MiB already allocated; 15.12 MiB free; 610.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:24:44,349 controller 1396628 deployment_state.py:674 - Exception in Replica(id='ngpec27k', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1413875, ip=10.130.253.103, actor_id=22db9c25deb41181a5c3240501000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f3e1c6ae790>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 593.93 MiB already allocated; 15.12 MiB free; 594.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:24:44,351 controller 1396628 deployment_state.py:674 - Exception in Replica(id='8kczhhvm', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1413903, ip=10.130.253.103, actor_id=4bd429485f05006038ca2dcf01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fa64c7f56d0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 229.51 MiB already allocated; 15.12 MiB free; 230.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:24:44,352 controller 1396628 deployment_state.py:2228 - Replica(id='rv88dzo1', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:24:44,353 controller 1396628 deployment_state.py:2228 - Replica(id='5bvsm66u', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:24:44,354 controller 1396628 deployment_state.py:2228 - Replica(id='b28gqzvj', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:24:44,354 controller 1396628 deployment_state.py:2228 - Replica(id='xl43e2o0', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:24:44,355 controller 1396628 deployment_state.py:2228 - Replica(id='eg1l28ap', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:24:44,356 controller 1396628 deployment_state.py:2228 - Replica(id='ngpec27k', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:24:44,357 controller 1396628 deployment_state.py:2228 - Replica(id='8kczhhvm', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:24:44,360 controller 1396628 deployment_state.py:1910 - Adding 7 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415968)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415968)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413903)[0m 2024-08-28 15:24:40.164844410 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413903)[0m 2024-08-28 15:24:40.164891444 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413903)[0m 2024-08-28 15:24:41,479 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413903)[0m [2024-08-28 15:24:41,479-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1413903] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413903)[0m 2024-08-28 15:24:41,479 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413903)[0m [2024-08-28 15:24:41,479-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1413903]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413903)[0m 2024-08-28 15:24:41,479 WETEXT INFO skip building fst for zh_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413903)[0m [2024-08-28 15:24:41,479-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1413903] skip building fst for zh_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413903)[0m 2024-08-28 15:24:42,395 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413903)[0m [2024-08-28 15:24:42,395-wetext-en_normalizer-processor.py-build_fst-95-INFO-1413903] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413903)[0m 2024-08-28 15:24:42,396 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413903)[0m [2024-08-28 15:24:42,396-wetext-en_normalizer-processor.py-build_fst-96-INFO-1413903]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413903)[0m 2024-08-28 15:24:42,396 WETEXT INFO skip building fst for en_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1413903)[0m [2024-08-28 15:24:42,396-wetext-en_normalizer-processor.py-build_fst-97-INFO-1413903] skip building fst for en_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:24:51,357 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415968)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415968)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415986)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415986)[0m   warnings.warn([32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415983)[0m [2024-08-28 15:25:00,357-root-flow.py-__init__-45-INFO-1415983] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415983)[0m 2024-08-28 15:25:04.880883938 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415983)[0m 2024-08-28 15:25:04.880929357 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415986)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415986)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415986)[0m [2024-08-28 15:25:00,815-root-flow.py-__init__-45-INFO-1415986] input frame rate=50[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415983)[0m 2024-08-28 15:25:05,742 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415983)[0m [2024-08-28 15:25:05,742-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1415983] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415983)[0m 2024-08-28 15:25:05,742 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415983)[0m [2024-08-28 15:25:05,742-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1415983]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415983)[0m 2024-08-28 15:25:05,743 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415983)[0m [2024-08-28 15:25:05,743-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1415983] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415983)[0m 2024-08-28 15:25:06,681 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415983)[0m [2024-08-28 15:25:06,681-wetext-en_normalizer-processor.py-build_fst-95-INFO-1415983] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415983)[0m 2024-08-28 15:25:06,681 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415983)[0m [2024-08-28 15:25:06,681-wetext-en_normalizer-processor.py-build_fst-96-INFO-1415983]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415983)[0m 2024-08-28 15:25:06,681 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415983)[0m [2024-08-28 15:25:06,681-wetext-en_normalizer-processor.py-build_fst-97-INFO-1415983] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:25:09,160 controller 1396628 deployment_state.py:674 - Exception in Replica(id='wl25ojhk', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1415968, ip=10.130.253.103, actor_id=3b0e505fa3051313834e569301000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fe26c0f5790>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 541.87 MiB already allocated; 11.12 MiB free; 542.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:25:09,162 controller 1396628 deployment_state.py:674 - Exception in Replica(id='es6tycli', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1415971, ip=10.130.253.103, actor_id=9fde9ce20ac4946a1385c5c501000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f32486ad7c0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 505.83 MiB already allocated; 11.12 MiB free; 506.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:25:09,164 controller 1396628 deployment_state.py:674 - Exception in Replica(id='r1biiyrc', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1415975, ip=10.130.253.103, actor_id=609f4105e4fcd45cbc3c437a01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f1454275760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 385.70 MiB already allocated; 11.12 MiB free; 386.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:25:09,166 controller 1396628 deployment_state.py:674 - Exception in Replica(id='9pkcs3ds', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1415979, ip=10.130.253.103, actor_id=f874f46ff4c957dc674efa8e01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fd5347f5760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 521.86 MiB already allocated; 11.12 MiB free; 522.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:25:09,168 controller 1396628 deployment_state.py:674 - Exception in Replica(id='xdx1a1es', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1415980, ip=10.130.253.103, actor_id=224aebcb560ee50bbf2f6eef01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f09ac775760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 281.57 MiB already allocated; 11.12 MiB free; 282.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:25:09,169 controller 1396628 deployment_state.py:674 - Exception in Replica(id='qagn8pyd', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1415983, ip=10.130.253.103, actor_id=996dcc5900d2ebfba52ced7101000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f4780275670>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 818.18 MiB already allocated; 11.12 MiB free; 820.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:25:09,171 controller 1396628 deployment_state.py:674 - Exception in Replica(id='doph1iqq', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1415986, ip=10.130.253.103, actor_id=55490b74026f0c91ea5ef12301000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f37ac2b5730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 349.65 MiB already allocated; 11.12 MiB free; 350.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:09,172 controller 1396628 deployment_state.py:2228 - Replica(id='wl25ojhk', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:09,173 controller 1396628 deployment_state.py:2228 - Replica(id='es6tycli', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:09,174 controller 1396628 deployment_state.py:2228 - Replica(id='r1biiyrc', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:09,175 controller 1396628 deployment_state.py:2228 - Replica(id='9pkcs3ds', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:09,176 controller 1396628 deployment_state.py:2228 - Replica(id='xdx1a1es', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:09,177 controller 1396628 deployment_state.py:2228 - Replica(id='qagn8pyd', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:09,177 controller 1396628 deployment_state.py:2228 - Replica(id='doph1iqq', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:09,181 controller 1396628 deployment_state.py:1910 - Adding 7 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417937)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417937)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415975)[0m 2024-08-28 15:25:05.395601208 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415975)[0m 2024-08-28 15:25:05.395645645 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415986)[0m 2024-08-28 15:25:06,165 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415986)[0m [2024-08-28 15:25:06,165-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1415986] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415986)[0m 2024-08-28 15:25:06,165 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415986)[0m [2024-08-28 15:25:06,165-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1415986]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415986)[0m 2024-08-28 15:25:06,165 WETEXT INFO skip building fst for zh_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415986)[0m [2024-08-28 15:25:06,165-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1415986] skip building fst for zh_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415980)[0m 2024-08-28 15:25:07,146 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415980)[0m [2024-08-28 15:25:07,146-wetext-en_normalizer-processor.py-build_fst-95-INFO-1415980] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415980)[0m 2024-08-28 15:25:07,146 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415980)[0m [2024-08-28 15:25:07,146-wetext-en_normalizer-processor.py-build_fst-96-INFO-1415980]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415980)[0m 2024-08-28 15:25:07,146 WETEXT INFO skip building fst for en_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1415980)[0m [2024-08-28 15:25:07,146-wetext-en_normalizer-processor.py-build_fst-97-INFO-1415980] skip building fst for en_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:25:21,375 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 7 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:25:21,375 controller 1396628 deployment_state.py:2212 - Deployment 'CosyVoiceWsRay' in application 'app1' has 1 replicas that have taken more than 30s to initialize. This may be caused by a slow __init__ or reconfigure method.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417934)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417934)[0m   warnings.warn([32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417937)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417937)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417935)[0m [2024-08-28 15:25:25,389-root-flow.py-__init__-45-INFO-1417935] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417940)[0m 2024-08-28 15:25:29.623824174 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417940)[0m 2024-08-28 15:25:29.623871661 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417939)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417939)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417940)[0m 2024-08-28 15:25:30,483 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417940)[0m [2024-08-28 15:25:30,483-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1417940] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417940)[0m 2024-08-28 15:25:30,483 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417940)[0m [2024-08-28 15:25:30,483-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1417940]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417940)[0m 2024-08-28 15:25:30,483 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417940)[0m [2024-08-28 15:25:30,483-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1417940] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417939)[0m [2024-08-28 15:25:25,638-root-flow.py-__init__-45-INFO-1417939] input frame rate=50[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417940)[0m 2024-08-28 15:25:31,641 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417940)[0m [2024-08-28 15:25:31,641-wetext-en_normalizer-processor.py-build_fst-95-INFO-1417940] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417940)[0m 2024-08-28 15:25:31,641 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417940)[0m [2024-08-28 15:25:31,641-wetext-en_normalizer-processor.py-build_fst-96-INFO-1417940]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417940)[0m 2024-08-28 15:25:31,641 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417940)[0m [2024-08-28 15:25:31,641-wetext-en_normalizer-processor.py-build_fst-97-INFO-1417940] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:25:34,257 controller 1396628 deployment_state.py:674 - Exception in Replica(id='qg3w0smt', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1417940, ip=10.130.253.103, actor_id=d02b32211c081c50f93d045501000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f3b447f4760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 886.27 MiB already allocated; 19.12 MiB free; 888.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:25:34,263 controller 1396628 deployment_state.py:674 - Exception in Replica(id='20fqwlzn', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1417934, ip=10.130.253.103, actor_id=dd59723d0fd6e0550275290401000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f7ccc7f5760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 401.71 MiB already allocated; 3.12 MiB free; 402.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:25:34,265 controller 1396628 deployment_state.py:674 - Exception in Replica(id='ph4eahjt', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1417935, ip=10.130.253.103, actor_id=171f66a8b2f87d32c271a56c01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f2c040b5760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 662.01 MiB already allocated; 3.12 MiB free; 664.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:25:34,266 controller 1396628 deployment_state.py:674 - Exception in Replica(id='octvrnlb', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1417936, ip=10.130.253.103, actor_id=46d1df4cbe9d155ccb53091601000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fb84c175700>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 453.77 MiB already allocated; 3.12 MiB free; 454.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:25:34,267 controller 1396628 deployment_state.py:674 - Exception in Replica(id='y7vgvdum', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1417937, ip=10.130.253.103, actor_id=bfd085c3dee6eb9a662dff6f01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f972413e760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 349.65 MiB already allocated; 3.12 MiB free; 350.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:25:34,269 controller 1396628 deployment_state.py:674 - Exception in Replica(id='7seqxdym', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1417938, ip=10.130.253.103, actor_id=f205edd1534dee9c94478c2c01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fdc9c72e760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 593.93 MiB already allocated; 3.12 MiB free; 594.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:25:34,270 controller 1396628 deployment_state.py:674 - Exception in Replica(id='lqrvbtsw', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1417939, ip=10.130.253.103, actor_id=e201aa5f96d14916ce44f37d01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fcb60775760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 573.92 MiB already allocated; 19.12 MiB free; 574.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:34,273 controller 1396628 deployment_state.py:2228 - Replica(id='qg3w0smt', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:34,274 controller 1396628 deployment_state.py:2228 - Replica(id='20fqwlzn', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:34,276 controller 1396628 deployment_state.py:2228 - Replica(id='ph4eahjt', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:34,278 controller 1396628 deployment_state.py:2228 - Replica(id='octvrnlb', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:34,280 controller 1396628 deployment_state.py:2228 - Replica(id='y7vgvdum', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:34,282 controller 1396628 deployment_state.py:2228 - Replica(id='7seqxdym', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:34,283 controller 1396628 deployment_state.py:2228 - Replica(id='lqrvbtsw', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:34,292 controller 1396628 deployment_state.py:1910 - Adding 7 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419889)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419889)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417939)[0m 2024-08-28 15:25:29.956136452 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417939)[0m 2024-08-28 15:25:29.956177172 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417934)[0m 2024-08-28 15:25:30,862 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417934)[0m [2024-08-28 15:25:30,862-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1417934] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417934)[0m 2024-08-28 15:25:30,863 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417934)[0m [2024-08-28 15:25:30,863-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1417934]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417934)[0m 2024-08-28 15:25:30,863 WETEXT INFO skip building fst for zh_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417934)[0m [2024-08-28 15:25:30,863-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1417934] skip building fst for zh_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417934)[0m 2024-08-28 15:25:32,119 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417934)[0m [2024-08-28 15:25:32,119-wetext-en_normalizer-processor.py-build_fst-95-INFO-1417934] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417934)[0m 2024-08-28 15:25:32,119 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417934)[0m [2024-08-28 15:25:32,119-wetext-en_normalizer-processor.py-build_fst-96-INFO-1417934]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417934)[0m 2024-08-28 15:25:32,119 WETEXT INFO skip building fst for en_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1417934)[0m [2024-08-28 15:25:32,119-wetext-en_normalizer-processor.py-build_fst-97-INFO-1417934] skip building fst for en_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419890)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419890)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419887)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419887)[0m   warnings.warn([32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419890)[0m [2024-08-28 15:25:50,405-root-flow.py-__init__-45-INFO-1419890] input frame rate=50
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:25:51,451 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 5 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:25:51,452 controller 1396628 deployment_state.py:2212 - Deployment 'CosyVoiceWsRay' in application 'app1' has 3 replicas that have taken more than 30s to initialize. This may be caused by a slow __init__ or reconfigure method.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419890)[0m 2024-08-28 15:25:54.588752937 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419890)[0m 2024-08-28 15:25:54.588797226 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419887)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419887)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419891)[0m [2024-08-28 15:25:50,906-root-flow.py-__init__-45-INFO-1419891] input frame rate=50[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419890)[0m 2024-08-28 15:25:55,434 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419890)[0m [2024-08-28 15:25:55,434-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1419890] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419890)[0m 2024-08-28 15:25:55,434 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419890)[0m [2024-08-28 15:25:55,434-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1419890]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419890)[0m 2024-08-28 15:25:55,435 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419890)[0m [2024-08-28 15:25:55,435-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1419890] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419890)[0m 2024-08-28 15:25:56,368 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419890)[0m [2024-08-28 15:25:56,368-wetext-en_normalizer-processor.py-build_fst-95-INFO-1419890] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419890)[0m 2024-08-28 15:25:56,368 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419890)[0m [2024-08-28 15:25:56,368-wetext-en_normalizer-processor.py-build_fst-96-INFO-1419890]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419890)[0m 2024-08-28 15:25:56,368 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419890)[0m [2024-08-28 15:25:56,368-wetext-en_normalizer-processor.py-build_fst-97-INFO-1419890] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:25:59,342 controller 1396628 deployment_state.py:674 - Exception in Replica(id='787ktzpj', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1419888, ip=10.130.253.103, actor_id=10d35b0d16eab1f10e727a2401000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7feadc6ae760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 609.95 MiB already allocated; 1.12 MiB free; 610.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:25:59,344 controller 1396628 deployment_state.py:674 - Exception in Replica(id='3qxef0k5', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1419889, ip=10.130.253.103, actor_id=005c7debd57478b99811637501000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7ff784775730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 678.03 MiB already allocated; 1.12 MiB free; 680.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:25:59,346 controller 1396628 deployment_state.py:674 - Exception in Replica(id='wf7f685c', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1419893, ip=10.130.253.103, actor_id=95b2a32aae2448f3de583cb001000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f6df06ee730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 141.41 MiB already allocated; 1.12 MiB free; 142.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:59,350 controller 1396628 deployment_state.py:2228 - Replica(id='787ktzpj', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:59,351 controller 1396628 deployment_state.py:2228 - Replica(id='3qxef0k5', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:59,352 controller 1396628 deployment_state.py:2228 - Replica(id='wf7f685c', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:59,358 controller 1396628 deployment_state.py:1910 - Adding 3 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:25:59,482 controller 1396628 deployment_state.py:674 - Exception in Replica(id='f8wxfvzq', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1419891, ip=10.130.253.103, actor_id=e64c3aba5269fdf5f14a79e501000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fc73c275730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 645.99 MiB already allocated; 1.12 MiB free; 646.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:25:59,485 controller 1396628 deployment_state.py:674 - Exception in Replica(id='j1vf6twm', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1419892, ip=10.130.253.103, actor_id=1a211fbdaa5289c8a1b1402f01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fb0f43fc730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 437.76 MiB already allocated; 1.12 MiB free; 438.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:25:59,488 controller 1396628 deployment_state.py:674 - Exception in Replica(id='v46191i3', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1419887, ip=10.130.253.103, actor_id=af25a598e645e3fcb40f29e801000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7ff5007757c0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 245.53 MiB already allocated; 1.12 MiB free; 246.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:59,494 controller 1396628 deployment_state.py:2228 - Replica(id='f8wxfvzq', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:59,494 controller 1396628 deployment_state.py:2228 - Replica(id='j1vf6twm', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:59,495 controller 1396628 deployment_state.py:2228 - Replica(id='v46191i3', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:25:59,499 controller 1396628 deployment_state.py:1910 - Adding 3 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421880)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421880)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419887)[0m 2024-08-28 15:25:55.480576476 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419887)[0m 2024-08-28 15:25:55.480619117 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419887)[0m 2024-08-28 15:25:56,462 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419887)[0m [2024-08-28 15:25:56,462-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1419887] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419887)[0m 2024-08-28 15:25:56,462 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419887)[0m [2024-08-28 15:25:56,462-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1419887]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419887)[0m 2024-08-28 15:25:56,462 WETEXT INFO skip building fst for zh_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419887)[0m [2024-08-28 15:25:56,462-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1419887] skip building fst for zh_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419887)[0m 2024-08-28 15:25:57,393 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419887)[0m [2024-08-28 15:25:57,393-wetext-en_normalizer-processor.py-build_fst-95-INFO-1419887] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419887)[0m 2024-08-28 15:25:57,393 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419887)[0m [2024-08-28 15:25:57,393-wetext-en_normalizer-processor.py-build_fst-96-INFO-1419887]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419887)[0m 2024-08-28 15:25:57,393 WETEXT INFO skip building fst for en_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419887)[0m [2024-08-28 15:25:57,393-wetext-en_normalizer-processor.py-build_fst-97-INFO-1419887] skip building fst for en_normalizer ...[32m [repeated 6x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421843)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421843)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421879)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 5x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421879)[0m   warnings.warn([32m [repeated 5x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421850)[0m [2024-08-28 15:26:15,629-root-flow.py-__init__-45-INFO-1421850] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421850)[0m 2024-08-28 15:26:19.736669143 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421850)[0m 2024-08-28 15:26:19.736710105 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421879)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 5x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421879)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 5x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421850)[0m 2024-08-28 15:26:20,486 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421850)[0m [2024-08-28 15:26:20,486-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1421850] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421850)[0m 2024-08-28 15:26:20,487 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421850)[0m [2024-08-28 15:26:20,487-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1421850]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421850)[0m 2024-08-28 15:26:20,487 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421850)[0m [2024-08-28 15:26:20,487-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1421850] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421841)[0m [2024-08-28 15:26:15,833-root-flow.py-__init__-45-INFO-1421841] input frame rate=50[32m [repeated 5x across cluster][0m
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:26:21,482 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 5 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:26:21,483 controller 1396628 deployment_state.py:2212 - Deployment 'CosyVoiceWsRay' in application 'app1' has 3 replicas that have taken more than 30s to initialize. This may be caused by a slow __init__ or reconfigure method.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421850)[0m 2024-08-28 15:26:21,799 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421850)[0m [2024-08-28 15:26:21,799-wetext-en_normalizer-processor.py-build_fst-95-INFO-1421850] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421850)[0m 2024-08-28 15:26:21,799 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421850)[0m [2024-08-28 15:26:21,799-wetext-en_normalizer-processor.py-build_fst-96-INFO-1421850]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421850)[0m 2024-08-28 15:26:21,799 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421850)[0m [2024-08-28 15:26:21,799-wetext-en_normalizer-processor.py-build_fst-97-INFO-1421850] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:26:24,800 controller 1396628 deployment_state.py:674 - Exception in Replica(id='lply2emw', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1421843, ip=10.130.253.103, actor_id=1611ed94c7611d8bd123add101000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f8df4b04790>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 802.17 MiB already allocated; 15.12 MiB free; 804.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:26:24,806 controller 1396628 deployment_state.py:674 - Exception in Replica(id='ty9llfao', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1421880, ip=10.130.253.103, actor_id=163d7fa34d2ee4f8a71cc34001000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f42786ae760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 229.51 MiB already allocated; 15.12 MiB free; 230.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:26:24,810 controller 1396628 deployment_state.py:2228 - Replica(id='lply2emw', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:26:24,814 controller 1396628 deployment_state.py:1910 - Adding 2 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421877)[0m 2024-08-28 15:26:20.605636571 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 5x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421877)[0m 2024-08-28 15:26:20.605681191 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 5x across cluster][0m
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:26:24,939 controller 1396628 deployment_state.py:674 - Exception in Replica(id='xbgt2g8x', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1421879, ip=10.130.253.103, actor_id=6cb198c98cc08d8a88397de801000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fd72c1b4790>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 1.26 MiB already allocated; 15.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:26:24,943 controller 1396628 deployment_state.py:2228 - Replica(id='ty9llfao', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:26:24,948 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:26:25,070 controller 1396628 deployment_state.py:674 - Exception in Replica(id='f0bwkgiw', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1421841, ip=10.130.253.103, actor_id=77efe9238d43279aaae951de01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f74b43bc760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 1.26 MiB already allocated; 15.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:26:25,072 controller 1396628 deployment_state.py:674 - Exception in Replica(id='n8l455fu', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1421877, ip=10.130.253.103, actor_id=e2473f10f4036d29b732a5e901000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fe61c3fc6a0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 1.26 MiB already allocated; 15.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:26:25,075 controller 1396628 deployment_state.py:2228 - Replica(id='xbgt2g8x', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:26:25,076 controller 1396628 deployment_state.py:2228 - Replica(id='f0bwkgiw', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:26:25,077 controller 1396628 deployment_state.py:2228 - Replica(id='n8l455fu', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:26:25,081 controller 1396628 deployment_state.py:1910 - Adding 2 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423769)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423769)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421877)[0m 2024-08-28 15:26:21,832 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 5x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421877)[0m [2024-08-28 15:26:21,832-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1421877] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 5x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421877)[0m 2024-08-28 15:26:21,832 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 5x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421877)[0m [2024-08-28 15:26:21,832-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1421877]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 5x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421877)[0m 2024-08-28 15:26:21,832 WETEXT INFO skip building fst for zh_normalizer ...[32m [repeated 5x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421877)[0m [2024-08-28 15:26:21,832-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1421877] skip building fst for zh_normalizer ...[32m [repeated 5x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421877)[0m 2024-08-28 15:26:22,936 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 5x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421877)[0m [2024-08-28 15:26:22,936-wetext-en_normalizer-processor.py-build_fst-95-INFO-1421877] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 5x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421877)[0m 2024-08-28 15:26:22,936 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 5x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421877)[0m [2024-08-28 15:26:22,936-wetext-en_normalizer-processor.py-build_fst-96-INFO-1421877]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 5x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421877)[0m 2024-08-28 15:26:22,936 WETEXT INFO skip building fst for en_normalizer ...[32m [repeated 5x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421877)[0m [2024-08-28 15:26:22,936-wetext-en_normalizer-processor.py-build_fst-97-INFO-1421877] skip building fst for en_normalizer ...[32m [repeated 5x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423769)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423769)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423788)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423788)[0m   warnings.warn([32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423769)[0m [2024-08-28 15:26:41,023-root-flow.py-__init__-45-INFO-1423769] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423769)[0m 2024-08-28 15:26:45.307617437 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423769)[0m 2024-08-28 15:26:45.307660334 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423788)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423788)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423769)[0m 2024-08-28 15:26:46,052 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423769)[0m [2024-08-28 15:26:46,052-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1423769] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423769)[0m 2024-08-28 15:26:46,052 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423769)[0m [2024-08-28 15:26:46,052-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1423769]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423769)[0m 2024-08-28 15:26:46,053 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423769)[0m [2024-08-28 15:26:46,053-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1423769] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423788)[0m [2024-08-28 15:26:41,700-root-flow.py-__init__-45-INFO-1423788] input frame rate=50[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423769)[0m 2024-08-28 15:26:46,981 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423769)[0m [2024-08-28 15:26:46,981-wetext-en_normalizer-processor.py-build_fst-95-INFO-1423769] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423769)[0m 2024-08-28 15:26:46,981 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423769)[0m [2024-08-28 15:26:46,981-wetext-en_normalizer-processor.py-build_fst-96-INFO-1423769]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423769)[0m 2024-08-28 15:26:46,981 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423769)[0m [2024-08-28 15:26:46,981-wetext-en_normalizer-processor.py-build_fst-97-INFO-1423769] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:26:49,108 controller 1396628 deployment_state.py:674 - Exception in Replica(id='1xrta06f', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1423769, ip=10.130.253.103, actor_id=1acce5813df002c85200593b01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f747c72e730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 489.81 MiB already allocated; 13.12 MiB free; 490.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:26:49,112 controller 1396628 deployment_state.py:674 - Exception in Replica(id='xqslrdp0', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1423786, ip=10.130.253.103, actor_id=a60148ec083e42b8d9116d3401000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f391c2b5760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 417.74 MiB already allocated; 13.12 MiB free; 418.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:26:49,114 controller 1396628 deployment_state.py:674 - Exception in Replica(id='uwg1h11j', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1423787, ip=10.130.253.103, actor_id=598cc70c1dfb1c5ecbe352a301000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f55007b5760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 141.41 MiB already allocated; 13.12 MiB free; 142.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:26:49,117 controller 1396628 deployment_state.py:2228 - Replica(id='1xrta06f', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:26:49,118 controller 1396628 deployment_state.py:2228 - Replica(id='xqslrdp0', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:26:49,122 controller 1396628 deployment_state.py:1910 - Adding 3 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:26:49,254 controller 1396628 deployment_state.py:674 - Exception in Replica(id='wwwurevg', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1423774, ip=10.130.253.103, actor_id=ea7c82ff9ddd0d4e09ee700001000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f82247f56d0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 1.26 MiB already allocated; 13.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:26:49,258 controller 1396628 deployment_state.py:2228 - Replica(id='uwg1h11j', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:26:49,265 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:26:49,386 controller 1396628 deployment_state.py:674 - Exception in Replica(id='vjlv1yur', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1423788, ip=10.130.253.103, actor_id=03f0bd34f4a2a062b1957def01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f12b42b5730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 1.26 MiB already allocated; 13.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:26:49,390 controller 1396628 deployment_state.py:2228 - Replica(id='wwwurevg', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:26:49,395 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:26:49,517 controller 1396628 deployment_state.py:2228 - Replica(id='vjlv1yur', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:26:51,487 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423788)[0m 2024-08-28 15:26:45.800150243 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423788)[0m 2024-08-28 15:26:45.800194117 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423788)[0m 2024-08-28 15:26:46,620 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423788)[0m [2024-08-28 15:26:46,620-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1423788] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423788)[0m 2024-08-28 15:26:46,620 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423788)[0m [2024-08-28 15:26:46,620-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1423788]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423788)[0m 2024-08-28 15:26:46,621 WETEXT INFO skip building fst for zh_normalizer ...[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423788)[0m [2024-08-28 15:26:46,621-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1423788] skip building fst for zh_normalizer ...[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425539)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425539)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423788)[0m 2024-08-28 15:26:47,566 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423788)[0m [2024-08-28 15:26:47,566-wetext-en_normalizer-processor.py-build_fst-95-INFO-1423788] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423788)[0m 2024-08-28 15:26:47,566 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423788)[0m [2024-08-28 15:26:47,566-wetext-en_normalizer-processor.py-build_fst-96-INFO-1423788]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423788)[0m 2024-08-28 15:26:47,566 WETEXT INFO skip building fst for en_normalizer ...[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1423788)[0m [2024-08-28 15:26:47,566-wetext-en_normalizer-processor.py-build_fst-97-INFO-1423788] skip building fst for en_normalizer ...[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425540)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425540)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425590)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425590)[0m   warnings.warn([32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425540)[0m [2024-08-28 15:27:05,304-root-flow.py-__init__-45-INFO-1425540] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425540)[0m 2024-08-28 15:27:09.284661032 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425540)[0m 2024-08-28 15:27:09.284706700 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425590)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425590)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425550)[0m 2024-08-28 15:27:10,120 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425550)[0m [2024-08-28 15:27:10,120-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1425550] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425550)[0m 2024-08-28 15:27:10,120 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425550)[0m [2024-08-28 15:27:10,120-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1425550]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425550)[0m 2024-08-28 15:27:10,121 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425550)[0m [2024-08-28 15:27:10,121-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1425550] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425590)[0m [2024-08-28 15:27:05,925-root-flow.py-__init__-45-INFO-1425590] input frame rate=50[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425550)[0m 2024-08-28 15:27:11,008 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425550)[0m [2024-08-28 15:27:11,008-wetext-en_normalizer-processor.py-build_fst-95-INFO-1425550] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425550)[0m 2024-08-28 15:27:11,008 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425550)[0m [2024-08-28 15:27:11,008-wetext-en_normalizer-processor.py-build_fst-96-INFO-1425550]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425550)[0m 2024-08-28 15:27:11,008 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425550)[0m [2024-08-28 15:27:11,008-wetext-en_normalizer-processor.py-build_fst-97-INFO-1425550] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:27:13,349 controller 1396628 deployment_state.py:674 - Exception in Replica(id='hyj06jms', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1425539, ip=10.130.253.103, actor_id=dfb1b3122a8c13393687bb2a01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7faf888be760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 37.29 MiB already allocated; 3.12 MiB free; 38.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:27:13,351 controller 1396628 deployment_state.py:674 - Exception in Replica(id='mnnmvzom', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1425540, ip=10.130.253.103, actor_id=bde7f51cb08f45c5578025fc01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f46a81b5790>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 89.35 MiB already allocated; 3.12 MiB free; 90.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:27:13,353 controller 1396628 deployment_state.py:674 - Exception in Replica(id='ooyprd61', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1425550, ip=10.130.253.103, actor_id=02e6df6c5231c1687170c52601000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fe45cb84730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 417.74 MiB already allocated; 3.12 MiB free; 418.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:27:13,356 controller 1396628 deployment_state.py:2228 - Replica(id='hyj06jms', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:27:13,356 controller 1396628 deployment_state.py:2228 - Replica(id='mnnmvzom', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:27:13,357 controller 1396628 deployment_state.py:2228 - Replica(id='ooyprd61', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:27:13,361 controller 1396628 deployment_state.py:1910 - Adding 3 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:27:13,741 controller 1396628 deployment_state.py:674 - Exception in Replica(id='bxmot0u6', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1425590, ip=10.130.253.103, actor_id=d548d6a012aabd164bf74e2e01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fce143bc700>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 1.26 MiB already allocated; 3.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:27:13,749 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:27:13,867 controller 1396628 deployment_state.py:2228 - Replica(id='bxmot0u6', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427433)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427433)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425590)[0m 2024-08-28 15:27:09.968454622 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425590)[0m 2024-08-28 15:27:09.968493435 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425570)[0m 2024-08-28 15:27:10,802 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425570)[0m [2024-08-28 15:27:10,802-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1425570] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425570)[0m 2024-08-28 15:27:10,803 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425570)[0m [2024-08-28 15:27:10,803-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1425570]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425570)[0m 2024-08-28 15:27:10,803 WETEXT INFO skip building fst for zh_normalizer ...[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425570)[0m [2024-08-28 15:27:10,803-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1425570] skip building fst for zh_normalizer ...[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425570)[0m 2024-08-28 15:27:12,110 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425570)[0m [2024-08-28 15:27:12,110-wetext-en_normalizer-processor.py-build_fst-95-INFO-1425570] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425570)[0m 2024-08-28 15:27:12,110 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425570)[0m [2024-08-28 15:27:12,110-wetext-en_normalizer-processor.py-build_fst-96-INFO-1425570]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425570)[0m 2024-08-28 15:27:12,110 WETEXT INFO skip building fst for en_normalizer ...[32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425570)[0m [2024-08-28 15:27:12,110-wetext-en_normalizer-processor.py-build_fst-97-INFO-1425570] skip building fst for en_normalizer ...[32m [repeated 4x across cluster][0m
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:27:21,544 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427434)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427434)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427521)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 3x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427521)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427434)[0m [2024-08-28 15:27:29,452-root-flow.py-__init__-45-INFO-1427434] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427435)[0m 2024-08-28 15:27:34.124300300 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427435)[0m 2024-08-28 15:27:34.124348778 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427521)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 3x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427521)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 3x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427521)[0m [2024-08-28 15:27:30,086-root-flow.py-__init__-45-INFO-1427521] input frame rate=50[32m [repeated 3x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427435)[0m 2024-08-28 15:27:35,132 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427435)[0m [2024-08-28 15:27:35,132-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1427435] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427435)[0m 2024-08-28 15:27:35,132 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427435)[0m [2024-08-28 15:27:35,132-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1427435]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427435)[0m 2024-08-28 15:27:35,132 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427435)[0m [2024-08-28 15:27:35,132-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1427435] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427434)[0m 2024-08-28 15:27:35.341051257 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 26214400
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427434)[0m 
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:27:35,367 controller 1396628 deployment_state.py:674 - Exception in Replica(id='x19qq6ug', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1427433, ip=10.130.253.103, actor_id=2764353b18ffe6bba70b877801000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f30501b56a0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 6553600
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:27:35,369 controller 1396628 deployment_state.py:674 - Exception in Replica(id='ys9xm20t', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1427434, ip=10.130.253.103, actor_id=e70cdddc7355e013c923065f01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fac886ee790>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 26214400
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:27:35,375 controller 1396628 deployment_state.py:1910 - Adding 2 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:27:35,497 controller 1396628 deployment_state.py:2228 - Replica(id='x19qq6ug', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:27:35,498 controller 1396628 deployment_state.py:2228 - Replica(id='ys9xm20t', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427435)[0m 2024-08-28 15:27:36,147 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427435)[0m [2024-08-28 15:27:36,147-wetext-en_normalizer-processor.py-build_fst-95-INFO-1427435] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427435)[0m 2024-08-28 15:27:36,147 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427435)[0m [2024-08-28 15:27:36,147-wetext-en_normalizer-processor.py-build_fst-96-INFO-1427435]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427435)[0m 2024-08-28 15:27:36,148 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427435)[0m [2024-08-28 15:27:36,148-wetext-en_normalizer-processor.py-build_fst-97-INFO-1427435] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:27:38,561 controller 1396628 deployment_state.py:674 - Exception in Replica(id='vj3ky41n', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1427435, ip=10.130.253.103, actor_id=c86b43fdd02e7c160c7e633501000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fe77c37c760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 750.11 MiB already allocated; 7.12 MiB free; 752.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:27:38,576 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:27:38,698 controller 1396628 deployment_state.py:674 - Exception in Replica(id='eoa39uoz', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1427521, ip=10.130.253.103, actor_id=aa3ff4624dcb906524f28bea01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fa0a41b5700>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 958.34 MiB already allocated; 7.12 MiB free; 960.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:27:38,701 controller 1396628 deployment_state.py:2228 - Replica(id='vj3ky41n', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:27:38,706 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:27:38,830 controller 1396628 deployment_state.py:2228 - Replica(id='eoa39uoz', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429008)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429008)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427433)[0m 2024-08-28 15:27:34.507895587 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 3x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427433)[0m 2024-08-28 15:27:34.507945005 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 3x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427521)[0m 2024-08-28 15:27:35,158 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427521)[0m [2024-08-28 15:27:35,158-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1427521] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427521)[0m 2024-08-28 15:27:35,159 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427521)[0m [2024-08-28 15:27:35,159-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1427521]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427521)[0m 2024-08-28 15:27:35,159 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427521)[0m [2024-08-28 15:27:35,159-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1427521] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427433)[0m 2024-08-28 15:27:35.321209313 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 6553600
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427433)[0m 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427521)[0m 2024-08-28 15:27:36,119 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427521)[0m [2024-08-28 15:27:36,119-wetext-en_normalizer-processor.py-build_fst-95-INFO-1427521] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427521)[0m 2024-08-28 15:27:36,119 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427521)[0m [2024-08-28 15:27:36,119-wetext-en_normalizer-processor.py-build_fst-96-INFO-1427521]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427521)[0m 2024-08-28 15:27:36,120 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1427521)[0m [2024-08-28 15:27:36,120-wetext-en_normalizer-processor.py-build_fst-97-INFO-1427521] skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429007)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429007)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429303)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 3x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429303)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429007)[0m [2024-08-28 15:27:51,589-root-flow.py-__init__-45-INFO-1429007] input frame rate=50
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:27:51,669 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429301)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 3x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429301)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 3x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429007)[0m 2024-08-28 15:27:55.818818269 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429007)[0m 2024-08-28 15:27:55.818851592 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429007)[0m 2024-08-28 15:27:56,652 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429007)[0m [2024-08-28 15:27:56,652-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1429007] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429007)[0m 2024-08-28 15:27:56,652 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429007)[0m [2024-08-28 15:27:56,652-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1429007]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429007)[0m 2024-08-28 15:27:56,652 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429007)[0m [2024-08-28 15:27:56,652-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1429007] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429301)[0m [2024-08-28 15:27:55,149-root-flow.py-__init__-45-INFO-1429301] input frame rate=50[32m [repeated 3x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429007)[0m 2024-08-28 15:27:57,625 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429007)[0m [2024-08-28 15:27:57,625-wetext-en_normalizer-processor.py-build_fst-95-INFO-1429007] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429007)[0m 2024-08-28 15:27:57,626 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429007)[0m [2024-08-28 15:27:57,626-wetext-en_normalizer-processor.py-build_fst-96-INFO-1429007]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429007)[0m 2024-08-28 15:27:57,626 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429007)[0m [2024-08-28 15:27:57,626-wetext-en_normalizer-processor.py-build_fst-97-INFO-1429007] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:27:59,897 controller 1396628 deployment_state.py:674 - Exception in Replica(id='47dwspx9', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1429007, ip=10.130.253.103, actor_id=00aa8c45e012fd253e52c6f901000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f6e74075730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 662.01 MiB already allocated; 1.12 MiB free; 664.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:27:59,901 controller 1396628 deployment_state.py:674 - Exception in Replica(id='o1b9x02m', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1429008, ip=10.130.253.103, actor_id=2470e68a14ca959dc5cd577301000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f2e0c72e790>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 297.59 MiB already allocated; 5.12 MiB free; 298.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:27:59,904 controller 1396628 deployment_state.py:674 - Exception in Replica(id='7jziqgay', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1429303, ip=10.130.253.103, actor_id=8612dad01610abed8f8b94cf01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f5ca07b4730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudnnStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudnnStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUDNN failure 1: CUDNN_STATUS_NOT_INITIALIZED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=172 ; expr=cudnnCreate(&cudnn_handle_);
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:27:59,906 controller 1396628 deployment_state.py:2228 - Replica(id='47dwspx9', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:27:59,910 controller 1396628 deployment_state.py:1910 - Adding 3 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429303)[0m 2024-08-28 15:27:59.860530816 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudnnStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudnnStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUDNN failure 1: CUDNN_STATUS_NOT_INITIALIZED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=172 ; expr=cudnnCreate(&cudnn_handle_); 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429303)[0m 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429303)[0m 
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:28:00,041 controller 1396628 deployment_state.py:674 - Exception in Replica(id='go8istj2', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1429301, ip=10.130.253.103, actor_id=0309fe4dda7e381f0dc6c25f01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fe9b07f56a0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_);
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:28:00,047 controller 1396628 deployment_state.py:2228 - Replica(id='o1b9x02m', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:28:00,048 controller 1396628 deployment_state.py:2228 - Replica(id='7jziqgay', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:28:00,050 controller 1396628 deployment_state.py:2228 - Replica(id='go8istj2', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:28:00,055 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429301)[0m 2024-08-28 15:27:59.975862555 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_); 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433890)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433890)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429301)[0m 2024-08-28 15:27:59.623503212 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 3x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429301)[0m 2024-08-28 15:27:59.623551842 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 3x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429008)[0m 2024-08-28 15:27:56,754 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429008)[0m [2024-08-28 15:27:56,754-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1429008] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429008)[0m 2024-08-28 15:27:56,754 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429008)[0m [2024-08-28 15:27:56,754-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1429008]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429008)[0m 2024-08-28 15:27:56,754 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429008)[0m [2024-08-28 15:27:56,754-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1429008] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429008)[0m 2024-08-28 15:27:57,720 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429008)[0m [2024-08-28 15:27:57,720-wetext-en_normalizer-processor.py-build_fst-95-INFO-1429008] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429008)[0m 2024-08-28 15:27:57,720 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429008)[0m [2024-08-28 15:27:57,720-wetext-en_normalizer-processor.py-build_fst-96-INFO-1429008]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429008)[0m 2024-08-28 15:27:57,720 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429008)[0m [2024-08-28 15:27:57,720-wetext-en_normalizer-processor.py-build_fst-97-INFO-1429008] skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1429301)[0m [32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433890)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433890)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433937)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 3x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433937)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433890)[0m [2024-08-28 15:28:16,215-root-flow.py-__init__-45-INFO-1433890] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433935)[0m 2024-08-28 15:28:21.145586480 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433935)[0m 2024-08-28 15:28:21.145645597 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433936)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 3x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433936)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 3x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433936)[0m [2024-08-28 15:28:16,357-root-flow.py-__init__-45-INFO-1433936] input frame rate=50[32m [repeated 3x across cluster][0m
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:28:21,734 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433935)[0m 2024-08-28 15:28:22,276 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433935)[0m [2024-08-28 15:28:22,276-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1433935] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433935)[0m 2024-08-28 15:28:22,276 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433935)[0m [2024-08-28 15:28:22,276-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1433935]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433935)[0m 2024-08-28 15:28:22,276 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433935)[0m [2024-08-28 15:28:22,276-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1433935] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433890)[0m 2024-08-28 15:28:22.519947895 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 26214400
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433890)[0m 
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:28:22,807 controller 1396628 deployment_state.py:674 - Exception in Replica(id='v7urtfez', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1433936, ip=10.130.253.103, actor_id=d9b5a6fe3a3d434801ac813401000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7ff7587b5790>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 56, in __init__
[36m(ServeController pid=1396628)[0m     self.spk2info = torch.load(spk2info, map_location=self.device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 31.74 GiB total capacity; 0 bytes already allocated; 1.12 MiB free; 0 bytes reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:28:22,809 controller 1396628 deployment_state.py:674 - Exception in Replica(id='kwod2npq', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1433937, ip=10.130.253.103, actor_id=3e0105c6597d8e1de59a275f01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f29208bf790>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 56, in __init__
[36m(ServeController pid=1396628)[0m     self.spk2info = torch.load(spk2info, map_location=self.device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 31.74 GiB total capacity; 0 bytes already allocated; 1.12 MiB free; 0 bytes reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:28:22,815 controller 1396628 deployment_state.py:1910 - Adding 2 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:28:22,933 controller 1396628 deployment_state.py:674 - Exception in Replica(id='4g62nzee', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1433890, ip=10.130.253.103, actor_id=d87e2287126b39028aa6791901000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f1edc7f56d0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 26214400
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:28:22,936 controller 1396628 deployment_state.py:2228 - Replica(id='v7urtfez', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:28:22,936 controller 1396628 deployment_state.py:2228 - Replica(id='kwod2npq', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:28:22,939 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:28:23,062 controller 1396628 deployment_state.py:2228 - Replica(id='4g62nzee', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433935)[0m 2024-08-28 15:28:23,384 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433935)[0m [2024-08-28 15:28:23,384-wetext-en_normalizer-processor.py-build_fst-95-INFO-1433935] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433935)[0m 2024-08-28 15:28:23,384 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433935)[0m [2024-08-28 15:28:23,384-wetext-en_normalizer-processor.py-build_fst-96-INFO-1433935]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433935)[0m 2024-08-28 15:28:23,384 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433935)[0m [2024-08-28 15:28:23,384-wetext-en_normalizer-processor.py-build_fst-97-INFO-1433935] skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1438086)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1438086)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433890)[0m 2024-08-28 15:28:21.630186981 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 3x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433890)[0m 2024-08-28 15:28:21.630230539 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 3x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1438086)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1438086)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1438089)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1438089)[0m   warnings.warn([32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1438086)[0m [2024-08-28 15:28:39,081-root-flow.py-__init__-45-INFO-1438086] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1438086)[0m 2024-08-28 15:28:44.408884322 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1438086)[0m 2024-08-28 15:28:44.408938695 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1438085)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1438085)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1438085)[0m [2024-08-28 15:28:39,372-root-flow.py-__init__-45-INFO-1438085] input frame rate=50[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1438086)[0m 2024-08-28 15:28:45.038834128 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 26214400
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1438086)[0m 
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:28:45,048 controller 1396628 deployment_state.py:674 - Exception in Replica(id='tagwxpq3', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1438086, ip=10.130.253.103, actor_id=9244b719581ff0a5009078f401000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7face8135730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 26214400
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:28:45,050 controller 1396628 deployment_state.py:674 - Exception in Replica(id='56m5kgdo', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1438089, ip=10.130.253.103, actor_id=10028917ec29f7a2b3bd8d6801000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f1dd4775670>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 26214400
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:28:45,057 controller 1396628 deployment_state.py:1910 - Adding 2 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:28:45,183 controller 1396628 deployment_state.py:674 - Exception in Replica(id='hohcg2vu', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1438085, ip=10.130.253.103, actor_id=42858ab36b975cfc30d0acb601000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fe3d87b5760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 6553600
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:28:45,186 controller 1396628 deployment_state.py:2228 - Replica(id='tagwxpq3', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:28:45,187 controller 1396628 deployment_state.py:2228 - Replica(id='56m5kgdo', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:28:45,192 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:28:45,309 controller 1396628 deployment_state.py:2228 - Replica(id='hohcg2vu', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1440331)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1440331)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1438089)[0m 2024-08-28 15:28:44.448823691 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1438089)[0m 2024-08-28 15:28:44.448866863 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1438085)[0m 2024-08-28 15:28:45.053990991 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 6553600[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1438085)[0m [32m [repeated 2x across cluster][0m
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:28:51,850 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1440328)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1440328)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1440340)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1440340)[0m   warnings.warn([32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1440328)[0m [2024-08-28 15:29:02,027-root-flow.py-__init__-45-INFO-1440328] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1440331)[0m 2024-08-28 15:29:06.479933785 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1440331)[0m 2024-08-28 15:29:06.479973523 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1440340)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1440340)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1440331)[0m 2024-08-28 15:29:07.078079734 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 26214400
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1440331)[0m 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1440331)[0m [2024-08-28 15:29:02,119-root-flow.py-__init__-45-INFO-1440331] input frame rate=50[32m [repeated 2x across cluster][0m
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:29:07,186 controller 1396628 deployment_state.py:674 - Exception in Replica(id='rt5foyk5', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1440328, ip=10.130.253.103, actor_id=212ace02e0670379dcbf677a01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fd8e46ae700>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 6553600
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:29:07,188 controller 1396628 deployment_state.py:674 - Exception in Replica(id='3ys34jnq', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1440331, ip=10.130.253.103, actor_id=f5df2675536c5f8d6b3b609a01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fdaa40be790>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 26214400
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:29:07,189 controller 1396628 deployment_state.py:674 - Exception in Replica(id='m60bj4hh', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1440340, ip=10.130.253.103, actor_id=aff03efc9293098ba06dd12301000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fad980b5760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 26214400
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:29:07,201 controller 1396628 deployment_state.py:1910 - Adding 3 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:29:07,334 controller 1396628 deployment_state.py:2228 - Replica(id='rt5foyk5', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:29:07,335 controller 1396628 deployment_state.py:2228 - Replica(id='3ys34jnq', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:29:07,336 controller 1396628 deployment_state.py:2228 - Replica(id='m60bj4hh', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1443263)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1443263)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1440340)[0m 2024-08-28 15:29:06.535128553 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1440340)[0m 2024-08-28 15:29:06.535165787 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1440340)[0m 2024-08-28 15:29:07.082523632 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 26214400[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1440340)[0m [32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1443263)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1443263)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1443266)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1443266)[0m   warnings.warn([32m [repeated 2x across cluster][0m
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:29:21,888 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1443263)[0m [2024-08-28 15:29:23,466-root-flow.py-__init__-45-INFO-1443263] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1443263)[0m 2024-08-28 15:29:27.623285318 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1443263)[0m 2024-08-28 15:29:27.623328971 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1443266)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1443266)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 2x across cluster][0m
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:29:28,486 controller 1396628 deployment_state.py:674 - Exception in Replica(id='4fvlmc0l', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1443263, ip=10.130.253.103, actor_id=413347b0797e956ac22d676801000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f16bc72e6d0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 26214400
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:29:28,494 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1443264)[0m [2024-08-28 15:29:23,919-root-flow.py-__init__-45-INFO-1443264] input frame rate=50[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1443263)[0m 2024-08-28 15:29:28.406437876 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 26214400
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1443263)[0m 
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:29:28,615 controller 1396628 deployment_state.py:674 - Exception in Replica(id='e4729hw7', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1443266, ip=10.130.253.103, actor_id=b32464389eb89254d315219801000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fe75c3fc730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_);
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:29:28,617 controller 1396628 deployment_state.py:2228 - Replica(id='4fvlmc0l', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:29:28,622 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1443266)[0m 2024-08-28 15:29:28.539135510 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_); 
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:29:28,744 controller 1396628 deployment_state.py:2228 - Replica(id='e4729hw7', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:29:28,988 controller 1396628 deployment_state.py:674 - Exception in Replica(id='ozxajj8x', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1443264, ip=10.130.253.103, actor_id=f98a37cc02da507c59f8adfe01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f13c03fc760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_);
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:29:28,995 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:29:29,113 controller 1396628 deployment_state.py:2228 - Replica(id='ozxajj8x', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1445583)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1445583)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1443264)[0m 2024-08-28 15:29:28.395100159 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1443264)[0m 2024-08-28 15:29:28.395144729 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1443264)[0m [32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1443264)[0m 2024-08-28 15:29:28.899807194 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_); 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1445585)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1445585)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1445627)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1445627)[0m   warnings.warn([32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1445585)[0m [2024-08-28 15:29:44,867-root-flow.py-__init__-45-INFO-1445585] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1445585)[0m 2024-08-28 15:29:49.208837112 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1445585)[0m 2024-08-28 15:29:49.208881194 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1445627)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1445627)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 2x across cluster][0m
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:29:49,945 controller 1396628 deployment_state.py:674 - Exception in Replica(id='1iq3uia0', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1445583, ip=10.130.253.103, actor_id=3d49248ec2793f8e36655a5501000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fe5ec33c730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 26214400
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:29:49,948 controller 1396628 deployment_state.py:674 - Exception in Replica(id='1wqye2cy', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1445585, ip=10.130.253.103, actor_id=2526fc526a88918e237cc08301000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f53886ae6a0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 6553600
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:29:49,950 controller 1396628 deployment_state.py:674 - Exception in Replica(id='siyuzf3l', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1445627, ip=10.130.253.103, actor_id=321597c8d0755e8a7ab3eac201000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f29cc37c730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudnnStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudnnStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUDNN failure 1: CUDNN_STATUS_NOT_INITIALIZED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=172 ; expr=cudnnCreate(&cudnn_handle_);
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:29:49,957 controller 1396628 deployment_state.py:1910 - Adding 3 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1445627)[0m [2024-08-28 15:29:45,089-root-flow.py-__init__-45-INFO-1445627] input frame rate=50[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1445583)[0m 2024-08-28 15:29:49.872511744 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 26214400
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1445583)[0m 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1445627)[0m 2024-08-28 15:29:49.869298778 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudnnStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudnnStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUDNN failure 1: CUDNN_STATUS_NOT_INITIALIZED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=172 ; expr=cudnnCreate(&cudnn_handle_); 
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:29:50,090 controller 1396628 deployment_state.py:2228 - Replica(id='1iq3uia0', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:29:50,091 controller 1396628 deployment_state.py:2228 - Replica(id='1wqye2cy', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:29:50,092 controller 1396628 deployment_state.py:2228 - Replica(id='siyuzf3l', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:29:51,918 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1447208)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1447208)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1445627)[0m 2024-08-28 15:29:49.326750939 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1445627)[0m 2024-08-28 15:29:49.326792842 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1445585)[0m 2024-08-28 15:29:49.881223770 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 6553600
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1445627)[0m [32m [repeated 3x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1447208)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1447208)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1447210)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1447210)[0m   warnings.warn([32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1447208)[0m [2024-08-28 15:30:06,131-root-flow.py-__init__-45-INFO-1447208] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1447208)[0m 2024-08-28 15:30:10.404529532 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1447208)[0m 2024-08-28 15:30:10.404570234 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1447210)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1447210)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1447208)[0m 2024-08-28 15:30:10.919219937 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 6553600
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1447208)[0m 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1447210)[0m 2024-08-28 15:30:10.956668410 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_); 
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:30:11,035 controller 1396628 deployment_state.py:674 - Exception in Replica(id='ol32xjmm', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1447208, ip=10.130.253.103, actor_id=f4584e329428c55a1c559fc401000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f3e8c1b5760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 6553600
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:30:11,037 controller 1396628 deployment_state.py:674 - Exception in Replica(id='slc8c9sz', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1447209, ip=10.130.253.103, actor_id=3f706e8f0b3b30928c801f5801000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7efe94775670>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 26214400
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:30:11,039 controller 1396628 deployment_state.py:674 - Exception in Replica(id='mgur46qb', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1447210, ip=10.130.253.103, actor_id=b66e77c10875de350f802aaf01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7ff36c37c6d0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_);
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:30:11,041 controller 1396628 deployment_state.py:2228 - Replica(id='slc8c9sz', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:30:11,043 controller 1396628 deployment_state.py:2228 - Replica(id='mgur46qb', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:30:11,052 controller 1396628 deployment_state.py:1910 - Adding 3 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:30:11,239 controller 1396628 deployment_state.py:2228 - Replica(id='ol32xjmm', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1447210)[0m [2024-08-28 15:30:06,386-root-flow.py-__init__-45-INFO-1447210] input frame rate=50[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1448780)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1448780)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1447210)[0m 2024-08-28 15:30:10.601820213 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1447210)[0m 2024-08-28 15:30:10.601856913 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1447209)[0m 2024-08-28 15:30:10.943423491 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 26214400
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1447210)[0m [32m [repeated 3x across cluster][0m
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:30:21,949 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1448957)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1448957)[0m   warnings.warn([32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1448781)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1448781)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1448781)[0m [2024-08-28 15:30:27,349-root-flow.py-__init__-45-INFO-1448781] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1448781)[0m 2024-08-28 15:30:31.596242149 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1448781)[0m 2024-08-28 15:30:31.596281486 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1448957)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1448957)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1448780)[0m 2024-08-28 15:30:32.184280987 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudnnStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudnnStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUDNN failure 4: CUDNN_STATUS_INTERNAL_ERROR ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=172 ; expr=cudnnCreate(&cudnn_handle_); 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1448780)[0m 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1448780)[0m 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1448781)[0m 2024-08-28 15:30:32.182007587 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 20971520
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:30:32,473 controller 1396628 deployment_state.py:674 - Exception in Replica(id='aa7pb210', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1448780, ip=10.130.253.103, actor_id=1b89e8ee85911eb1d7470c2201000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fb3582f5730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudnnStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudnnStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUDNN failure 4: CUDNN_STATUS_INTERNAL_ERROR ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=172 ; expr=cudnnCreate(&cudnn_handle_);
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:30:32,475 controller 1396628 deployment_state.py:674 - Exception in Replica(id='mkuj10y3', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1448781, ip=10.130.253.103, actor_id=f708866f9e3825533814353601000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fb5d82f56d0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 20971520
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1448957)[0m [2024-08-28 15:30:28,025-root-flow.py-__init__-45-INFO-1448957] input frame rate=50[32m [repeated 2x across cluster][0m
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:30:32,478 controller 1396628 deployment_state.py:2228 - Replica(id='aa7pb210', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:30:32,480 controller 1396628 deployment_state.py:2228 - Replica(id='mkuj10y3', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:30:32,487 controller 1396628 deployment_state.py:1910 - Adding 2 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1448957)[0m 2024-08-28 15:30:32.572182723 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_); 
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:30:32,977 controller 1396628 deployment_state.py:674 - Exception in Replica(id='w76rew1p', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1448957, ip=10.130.253.103, actor_id=dd725d6873625202fad7ba6a01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f9c287f5790>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_);
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:30:32,983 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:30:33,105 controller 1396628 deployment_state.py:2228 - Replica(id='w76rew1p', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1450360)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1450360)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1448957)[0m 2024-08-28 15:30:32.234060287 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1448957)[0m 2024-08-28 15:30:32.234098156 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1448957)[0m [32m [repeated 3x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1450360)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1450360)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1450481)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1450481)[0m   warnings.warn([32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1450360)[0m [2024-08-28 15:30:48,605-root-flow.py-__init__-45-INFO-1450360] input frame rate=50
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:30:51,972 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1450481)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1450481)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1450360)[0m 2024-08-28 15:30:52.812574049 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1450360)[0m 2024-08-28 15:30:52.812616134 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1450360)[0m 2024-08-28 15:30:53.415996745 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 26214400
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1450360)[0m 
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:30:53,680 controller 1396628 deployment_state.py:674 - Exception in Replica(id='py4l0zlk', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1450360, ip=10.130.253.103, actor_id=1530d33c606ad5167338d10701000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f13ec37c700>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 26214400
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:30:53,687 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1450481)[0m [2024-08-28 15:30:49,041-root-flow.py-__init__-45-INFO-1450481] input frame rate=50[32m [repeated 2x across cluster][0m
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:30:53,814 controller 1396628 deployment_state.py:2228 - Replica(id='py4l0zlk', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:30:53,936 controller 1396628 deployment_state.py:674 - Exception in Replica(id='j997jv8a', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1450481, ip=10.130.253.103, actor_id=e12a3d508d827c50200fb27001000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f2ab82b5700>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_);
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:30:53,943 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1450481)[0m 2024-08-28 15:30:53.921002516 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_); 
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:30:54,068 controller 1396628 deployment_state.py:674 - Exception in Replica(id='wgjuphc5', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1450364, ip=10.130.253.103, actor_id=af6988e4eeb8ee972279afc801000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f2ed87f5760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_);
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:30:54,071 controller 1396628 deployment_state.py:2228 - Replica(id='j997jv8a', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:30:54,075 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:30:54,199 controller 1396628 deployment_state.py:2228 - Replica(id='wgjuphc5', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451915)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451915)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1450364)[0m 2024-08-28 15:30:53.609633291 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1450364)[0m 2024-08-28 15:30:53.609667542 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1450364)[0m [32m [repeated 4x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1450364)[0m 2024-08-28 15:30:53.986536332 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_); 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451915)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451915)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451949)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451949)[0m   warnings.warn([32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451915)[0m [2024-08-28 15:31:09,194-root-flow.py-__init__-45-INFO-1451915] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451915)[0m 2024-08-28 15:31:13.516263845 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451915)[0m 2024-08-28 15:31:13.516304789 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451949)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451949)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451915)[0m 2024-08-28 15:31:14.110409844 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 26214400
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451915)[0m 
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:31:14,212 controller 1396628 deployment_state.py:674 - Exception in Replica(id='6gken9qu', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1451915, ip=10.130.253.103, actor_id=abad3ac4be0d0e706f6f718901000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f28187f47c0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:376 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream*, bool, onnxruntime::WaitNotificationFn) Failed to allocate memory for requested buffer of size 26214400
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:31:14,218 controller 1396628 deployment_state.py:2228 - Replica(id='6gken9qu', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:31:14,224 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451949)[0m [2024-08-28 15:31:10,362-root-flow.py-__init__-45-INFO-1451949] input frame rate=50[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451947)[0m 2024-08-28 15:31:15,108 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451947)[0m [2024-08-28 15:31:15,108-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1451947] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451947)[0m 2024-08-28 15:31:15,108 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451947)[0m [2024-08-28 15:31:15,108-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1451947]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451947)[0m 2024-08-28 15:31:15,108 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451947)[0m [2024-08-28 15:31:15,108-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1451947] skip building fst for zh_normalizer ...
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:31:15,561 controller 1396628 deployment_state.py:674 - Exception in Replica(id='ekbp52g2', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1451949, ip=10.130.253.103, actor_id=17ee2c6de0b2df5a99ce74a001000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fdb84343730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m RuntimeError: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUDA failure 2: out of memory ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=239 ; expr=cudaDeviceSynchronize(); 
[36m(ServeController pid=1396628)[0m The above exception was the direct cause of the following exception:
[36m(ServeController pid=1396628)[0m [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1451949, ip=10.130.253.103, actor_id=17ee2c6de0b2df5a99ce74a001000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fdb84343730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 430, in __init__
[36m(ServeController pid=1396628)[0m     raise fallback_error from e
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 425, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(self._fallback_providers, None)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_);
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:31:15,569 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451949)[0m 2024-08-28 15:31:15.542053054 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_); 
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:31:15,692 controller 1396628 deployment_state.py:2228 - Replica(id='ekbp52g2', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451947)[0m 2024-08-28 15:31:15,992 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451947)[0m [2024-08-28 15:31:15,992-wetext-en_normalizer-processor.py-build_fst-95-INFO-1451947] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451947)[0m 2024-08-28 15:31:15,993 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451947)[0m [2024-08-28 15:31:15,993-wetext-en_normalizer-processor.py-build_fst-96-INFO-1451947]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451947)[0m 2024-08-28 15:31:15,993 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451947)[0m [2024-08-28 15:31:15,993-wetext-en_normalizer-processor.py-build_fst-97-INFO-1451947] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:31:17,892 controller 1396628 deployment_state.py:674 - Exception in Replica(id='x90j4iw3', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1451947, ip=10.130.253.103, actor_id=5353cf27eb1a6a054406d55e01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f1d7472e730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 365.68 MiB already allocated; 11.12 MiB free; 366.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:31:17,898 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:31:18,023 controller 1396628 deployment_state.py:2228 - Replica(id='x90j4iw3', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453389)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453389)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451947)[0m 2024-08-28 15:31:14.386233293 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451947)[0m 2024-08-28 15:31:14.386278741 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451949)[0m [32m [repeated 6x across cluster][0m
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:31:22,011 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453389)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453389)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453747)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453747)[0m   warnings.warn([32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453389)[0m [2024-08-28 15:31:30,581-root-flow.py-__init__-45-INFO-1453389] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453747)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453747)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453389)[0m 2024-08-28 15:31:34.603571449 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453389)[0m 2024-08-28 15:31:34.603607719 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453389)[0m 2024-08-28 15:31:35,327 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453389)[0m [2024-08-28 15:31:35,327-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1453389] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453389)[0m 2024-08-28 15:31:35,327 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453389)[0m [2024-08-28 15:31:35,327-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1453389]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453389)[0m 2024-08-28 15:31:35,328 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453389)[0m [2024-08-28 15:31:35,328-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1453389] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453389)[0m 2024-08-28 15:31:36,176 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453389)[0m [2024-08-28 15:31:36,176-wetext-en_normalizer-processor.py-build_fst-95-INFO-1453389] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453389)[0m 2024-08-28 15:31:36,176 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453389)[0m [2024-08-28 15:31:36,176-wetext-en_normalizer-processor.py-build_fst-96-INFO-1453389]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453389)[0m 2024-08-28 15:31:36,176 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453389)[0m [2024-08-28 15:31:36,176-wetext-en_normalizer-processor.py-build_fst-97-INFO-1453389] skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453747)[0m [2024-08-28 15:31:34,347-root-flow.py-__init__-45-INFO-1453747] input frame rate=50[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453541)[0m 2024-08-28 15:31:36.493012817 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_); 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453541)[0m 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453541)[0m 
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:31:36,589 controller 1396628 deployment_state.py:674 - Exception in Replica(id='qjabcxa0', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1453541, ip=10.130.253.103, actor_id=0371aba0e910f8125310e3f001000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f95a86ae730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_);
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:31:36,596 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:31:36,719 controller 1396628 deployment_state.py:2228 - Replica(id='qjabcxa0', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:31:37,842 controller 1396628 deployment_state.py:674 - Exception in Replica(id='7kt1qix6', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1453389, ip=10.130.253.103, actor_id=2fe4b47810bb06e5ce2a7b1301000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f3b54075700>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 1.26 MiB already allocated; 7.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:31:37,849 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:31:37,968 controller 1396628 deployment_state.py:2228 - Replica(id='7kt1qix6', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453747)[0m 2024-08-28 15:31:38.642535076 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453747)[0m 2024-08-28 15:31:38.642575546 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453747)[0m 2024-08-28 15:31:39,372 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453747)[0m [2024-08-28 15:31:39,372-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1453747] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453747)[0m 2024-08-28 15:31:39,372 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453747)[0m [2024-08-28 15:31:39,372-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1453747]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453747)[0m 2024-08-28 15:31:39,372 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453747)[0m [2024-08-28 15:31:39,372-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1453747] skip building fst for zh_normalizer ...
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:31:41,867 controller 1396628 deployment_state.py:674 - Exception in Replica(id='rsso1p3c', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1453747, ip=10.130.253.103, actor_id=dd50e469394e5d325aa5ec8901000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f92f8275730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 1.26 MiB already allocated; 1.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:31:41,874 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453747)[0m 2024-08-28 15:31:40,248 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453747)[0m [2024-08-28 15:31:40,248-wetext-en_normalizer-processor.py-build_fst-95-INFO-1453747] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453747)[0m 2024-08-28 15:31:40,249 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453747)[0m [2024-08-28 15:31:40,249-wetext-en_normalizer-processor.py-build_fst-96-INFO-1453747]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453747)[0m 2024-08-28 15:31:40,249 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1453747)[0m [2024-08-28 15:31:40,249-wetext-en_normalizer-processor.py-build_fst-97-INFO-1453747] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:31:41,996 controller 1396628 deployment_state.py:2228 - Replica(id='rsso1p3c', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455051)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455051)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455619)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455619)[0m   warnings.warn([32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455051)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455051)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:31:52,069 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455051)[0m [2024-08-28 15:31:52,842-root-flow.py-__init__-45-INFO-1455051] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455619)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455619)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455051)[0m 2024-08-28 15:31:56.948732187 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455051)[0m 2024-08-28 15:31:56.948775398 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455051)[0m 2024-08-28 15:31:57,684 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455051)[0m [2024-08-28 15:31:57,684-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1455051] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455051)[0m 2024-08-28 15:31:57,684 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455051)[0m [2024-08-28 15:31:57,684-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1455051]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455051)[0m 2024-08-28 15:31:57,684 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455051)[0m [2024-08-28 15:31:57,684-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1455051] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455619)[0m [2024-08-28 15:31:58,288-root-flow.py-__init__-45-INFO-1455619] input frame rate=50[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455051)[0m 2024-08-28 15:31:58,579 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455051)[0m [2024-08-28 15:31:58,579-wetext-en_normalizer-processor.py-build_fst-95-INFO-1455051] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455051)[0m 2024-08-28 15:31:58,580 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455051)[0m [2024-08-28 15:31:58,580-wetext-en_normalizer-processor.py-build_fst-96-INFO-1455051]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455051)[0m 2024-08-28 15:31:58,580 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455051)[0m [2024-08-28 15:31:58,580-wetext-en_normalizer-processor.py-build_fst-97-INFO-1455051] skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455232)[0m 2024-08-28 15:31:58.972493174 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_); 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455232)[0m 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455232)[0m 
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:31:59,033 controller 1396628 deployment_state.py:674 - Exception in Replica(id='8mbibk4l', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1455232, ip=10.130.253.103, actor_id=e0ab4309dde88c75ae54520801000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f8e040f5700>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_);
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:31:59,041 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:31:59,164 controller 1396628 deployment_state.py:2228 - Replica(id='8mbibk4l', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:32:00,505 controller 1396628 deployment_state.py:674 - Exception in Replica(id='9aef563n', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1455051, ip=10.130.253.103, actor_id=cf935eedfa7f1f9a10e274aa01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f13f4235670>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 365.68 MiB already allocated; 9.12 MiB free; 366.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:32:00,514 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:32:00,636 controller 1396628 deployment_state.py:2228 - Replica(id='9aef563n', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455619)[0m 2024-08-28 15:32:02.460234695 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455619)[0m 2024-08-28 15:32:02.460272238 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455619)[0m 2024-08-28 15:32:03,173 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455619)[0m [2024-08-28 15:32:03,173-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1455619] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455619)[0m 2024-08-28 15:32:03,173 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455619)[0m [2024-08-28 15:32:03,173-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1455619]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455619)[0m 2024-08-28 15:32:03,173 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455619)[0m [2024-08-28 15:32:03,173-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1455619] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455619)[0m 2024-08-28 15:32:04,028 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455619)[0m [2024-08-28 15:32:04,028-wetext-en_normalizer-processor.py-build_fst-95-INFO-1455619] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455619)[0m 2024-08-28 15:32:04,028 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455619)[0m [2024-08-28 15:32:04,028-wetext-en_normalizer-processor.py-build_fst-96-INFO-1455619]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455619)[0m 2024-08-28 15:32:04,028 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1455619)[0m [2024-08-28 15:32:04,028-wetext-en_normalizer-processor.py-build_fst-97-INFO-1455619] skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1456847)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1456847)[0m   warnings.warn(
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:32:05,586 controller 1396628 deployment_state.py:674 - Exception in Replica(id='e9n03sp7', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1455619, ip=10.130.253.103, actor_id=cc54be30e240fd19e0fa153201000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fafc80b5730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 1.26 MiB already allocated; 7.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:32:05,595 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:32:05,717 controller 1396628 deployment_state.py:2228 - Replica(id='e9n03sp7', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1457555)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1457555)[0m   warnings.warn([32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1456847)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1456847)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1456847)[0m [2024-08-28 15:32:15,569-root-flow.py-__init__-45-INFO-1456847] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1457555)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1457555)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1456847)[0m 2024-08-28 15:32:19.634840239 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1456847)[0m 2024-08-28 15:32:19.634886957 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1456847)[0m 2024-08-28 15:32:20,336 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1456847)[0m [2024-08-28 15:32:20,336-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1456847] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1456847)[0m 2024-08-28 15:32:20,336 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1456847)[0m [2024-08-28 15:32:20,336-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1456847]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1456847)[0m 2024-08-28 15:32:20,337 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1456847)[0m [2024-08-28 15:32:20,337-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1456847] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1457049)[0m [2024-08-28 15:32:16,817-root-flow.py-__init__-45-INFO-1457049] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1457049)[0m 2024-08-28 15:32:21.169686434 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_); 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1457049)[0m 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1457049)[0m 
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:32:21,201 controller 1396628 deployment_state.py:674 - Exception in Replica(id='4kp7tw6v', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1457049, ip=10.130.253.103, actor_id=0340bc1bb1580a37d63021ce01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fc9306ee730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_);
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:32:21,207 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:32:21,327 controller 1396628 deployment_state.py:2228 - Replica(id='4kp7tw6v', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1456847)[0m 2024-08-28 15:32:21,638 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1456847)[0m [2024-08-28 15:32:21,638-wetext-en_normalizer-processor.py-build_fst-95-INFO-1456847] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1456847)[0m 2024-08-28 15:32:21,638 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1456847)[0m [2024-08-28 15:32:21,638-wetext-en_normalizer-processor.py-build_fst-96-INFO-1456847]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1456847)[0m 2024-08-28 15:32:21,639 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1456847)[0m [2024-08-28 15:32:21,639-wetext-en_normalizer-processor.py-build_fst-97-INFO-1456847] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:32:22,181 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1457555)[0m [2024-08-28 15:32:22,337-root-flow.py-__init__-45-INFO-1457555] input frame rate=50
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:32:23,611 controller 1396628 deployment_state.py:674 - Exception in Replica(id='lybfhprg', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1456847, ip=10.130.253.103, actor_id=1f96a8748c6af58babef6f0001000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f07a02747c0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 365.68 MiB already allocated; 11.12 MiB free; 366.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:32:23,618 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:32:23,740 controller 1396628 deployment_state.py:2228 - Replica(id='lybfhprg', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1457555)[0m 2024-08-28 15:32:26.225676792 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1457555)[0m 2024-08-28 15:32:26.225729474 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 2x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1457555)[0m 2024-08-28 15:32:26,949 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1457555)[0m [2024-08-28 15:32:26,949-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1457555] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1457555)[0m 2024-08-28 15:32:26,949 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1457555)[0m [2024-08-28 15:32:26,949-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1457555]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1457555)[0m 2024-08-28 15:32:26,949 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1457555)[0m [2024-08-28 15:32:26,949-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1457555] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458683)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458683)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1457555)[0m 2024-08-28 15:32:27,832 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1457555)[0m [2024-08-28 15:32:27,832-wetext-en_normalizer-processor.py-build_fst-95-INFO-1457555] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1457555)[0m 2024-08-28 15:32:27,832 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1457555)[0m [2024-08-28 15:32:27,832-wetext-en_normalizer-processor.py-build_fst-96-INFO-1457555]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1457555)[0m 2024-08-28 15:32:27,832 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1457555)[0m [2024-08-28 15:32:27,832-wetext-en_normalizer-processor.py-build_fst-97-INFO-1457555] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:32:29,493 controller 1396628 deployment_state.py:674 - Exception in Replica(id='mrtqhghv', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1457555, ip=10.130.253.103, actor_id=c2607cf9b7b3944ea9e57a2a01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f5f4c6ae700>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)2024-08-28 15:21:08,421	INFO scripts.py:492 -- Running config file: 'server.conf'.
2024-08-28 15:21:15,639	SUCC scripts.py:543 -- [32mSubmitted deploy config successfully.[39m
[36m(autoscaler +38s)[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.
[33m(autoscaler +38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 0.5}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1401641)[0m 模型权重加载成功
[33m(autoscaler +1m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 0.5}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[33m(autoscaler +1m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 0.5}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[33m(autoscaler +2m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 0.5}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[33m(autoscaler +2m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 0.5}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[33m(autoscaler +3m33s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 0.5}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[33m(autoscaler +4m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 0.5}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[33m(autoscaler +4m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 0.5}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1419890)[0m 模型权重加载成功
[33m(autoscaler +5m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 0.5}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1421850)[0m 模型权重加载成功
[33m(autoscaler +5m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 0.5}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1425570)[0m 模型权重加载成功
[33m(autoscaler +6m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 0.5}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[33m(autoscaler +7m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 0.5}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1433935)[0m 模型权重加载成功
[33m(autoscaler +7m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 0.5}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[33m(autoscaler +8m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 0.5}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[33m(autoscaler +8m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 0.5}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[33m(autoscaler +9m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 0.5}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[33m(autoscaler +9m59s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 0.5}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451949)[0m EP Error /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUDA failure 2: out of memory ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=239 ; expr=cudaDeviceSynchronize(); 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451949)[0m 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451949)[0m  when using ['CUDAExecutionProvider']
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1451949)[0m Falling back to ['CUDAExecutionProvider', 'CPUExecutionProvider'] and retrying.
[33m(autoscaler +10m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 0.5}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[33m(autoscaler +11m9s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 0.5}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458935)[0m EP Error /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUDA failure 2: out of memory ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=239 ; expr=cudaDeviceSynchronize(); 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458935)[0m 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458935)[0m  when using ['CUDAExecutionProvider']
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458935)[0m Falling back to ['CUDAExecutionProvider', 'CPUExecutionProvider'] and retrying.
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 1.26 MiB already allocated; 1.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:32:29,500 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:32:29,622 controller 1396628 deployment_state.py:2228 - Replica(id='mrtqhghv', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458683)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458683)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458935)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458935)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1459433)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1459433)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458683)[0m [2024-08-28 15:32:37,704-root-flow.py-__init__-45-INFO-1458683] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458683)[0m 2024-08-28 15:32:41.794929851 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458683)[0m 2024-08-28 15:32:41.794966578 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458935)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458935)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458683)[0m 2024-08-28 15:32:42,503 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458683)[0m [2024-08-28 15:32:42,503-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1458683] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458683)[0m 2024-08-28 15:32:42,503 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458683)[0m [2024-08-28 15:32:42,503-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1458683]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458683)[0m 2024-08-28 15:32:42,503 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458683)[0m [2024-08-28 15:32:42,503-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1458683] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1459433)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1459433)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458935)[0m [2024-08-28 15:32:40,086-root-flow.py-__init__-45-INFO-1458935] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458683)[0m 2024-08-28 15:32:43,420 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458683)[0m [2024-08-28 15:32:43,420-wetext-en_normalizer-processor.py-build_fst-95-INFO-1458683] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458683)[0m 2024-08-28 15:32:43,420 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458683)[0m [2024-08-28 15:32:43,420-wetext-en_normalizer-processor.py-build_fst-96-INFO-1458683]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458683)[0m 2024-08-28 15:32:43,420 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1458683)[0m [2024-08-28 15:32:43,420-wetext-en_normalizer-processor.py-build_fst-97-INFO-1458683] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:32:43,562 controller 1396628 deployment_state.py:674 - Exception in Replica(id='w628ct9c', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1458935, ip=10.130.253.103, actor_id=afc198d90978bc636237257201000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fa3c4075730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m RuntimeError: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUDA failure 2: out of memory ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=239 ; expr=cudaDeviceSynchronize(); 
[36m(ServeController pid=1396628)[0m 
[36m(ServeController pid=1396628)[0m 
[36m(ServeController pid=1396628)[0m 
[36m(ServeController pid=1396628)[0m The above exception was the direct cause of the following exception:
[36m(ServeController pid=1396628)[0m 
[36m(ServeController pid=1396628)[0m [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1458935, ip=10.130.253.103, actor_id=afc198d90978bc636237257201000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fa3c4075730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 430, in __init__
[36m(ServeController pid=1396628)[0m     raise fallback_error from e
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 425, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(self._fallback_providers, None)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m RuntimeError: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUDA failure 2: out of memory ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=239 ; expr=cudaDeviceSynchronize();
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:32:43,569 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:32:43,688 controller 1396628 deployment_state.py:2228 - Replica(id='w628ct9c', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:32:45,045 controller 1396628 deployment_state.py:674 - Exception in Replica(id='2z7bfk3z', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1458683, ip=10.130.253.103, actor_id=21496da73b0d4f0e7b4cf3cf01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fb3dc6ae6a0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 1.26 MiB already allocated; 9.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:32:45,053 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:32:45,174 controller 1396628 deployment_state.py:2228 - Replica(id='2z7bfk3z', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1459433)[0m [2024-08-28 15:32:46,115-root-flow.py-__init__-45-INFO-1459433] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460467)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460467)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1459433)[0m 2024-08-28 15:32:50.085166390 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1459433)[0m 2024-08-28 15:32:50.085214288 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1459433)[0m 2024-08-28 15:32:51,038 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1459433)[0m [2024-08-28 15:32:51,038-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1459433] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1459433)[0m 2024-08-28 15:32:51,039 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1459433)[0m [2024-08-28 15:32:51,039-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1459433]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1459433)[0m 2024-08-28 15:32:51,039 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1459433)[0m [2024-08-28 15:32:51,039-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1459433] skip building fst for zh_normalizer ...
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:32:52,247 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1459433)[0m 2024-08-28 15:32:52,359 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1459433)[0m [2024-08-28 15:32:52,359-wetext-en_normalizer-processor.py-build_fst-95-INFO-1459433] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1459433)[0m 2024-08-28 15:32:52,359 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1459433)[0m [2024-08-28 15:32:52,359-wetext-en_normalizer-processor.py-build_fst-96-INFO-1459433]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1459433)[0m 2024-08-28 15:32:52,359 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1459433)[0m [2024-08-28 15:32:52,359-wetext-en_normalizer-processor.py-build_fst-97-INFO-1459433] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:32:53,954 controller 1396628 deployment_state.py:674 - Exception in Replica(id='lcghot92', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1459433, ip=10.130.253.103, actor_id=c23c281b6224d4a46168215e01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f28902756a0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 1.26 MiB already allocated; 9.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:32:53,964 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:32:54,086 controller 1396628 deployment_state.py:2228 - Replica(id='lcghot92', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460467)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460467)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460646)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460646)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460467)[0m [2024-08-28 15:32:59,888-root-flow.py-__init__-45-INFO-1460467] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1461353)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1461353)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460467)[0m 2024-08-28 15:33:04.275037287 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460467)[0m 2024-08-28 15:33:04.275079625 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460646)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460646)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460467)[0m 2024-08-28 15:33:04,998 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460467)[0m [2024-08-28 15:33:04,998-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1460467] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460467)[0m 2024-08-28 15:33:04,998 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460467)[0m [2024-08-28 15:33:04,998-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1460467]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460467)[0m 2024-08-28 15:33:04,999 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460467)[0m [2024-08-28 15:33:04,999-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1460467] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460646)[0m [2024-08-28 15:33:01,577-root-flow.py-__init__-45-INFO-1460646] input frame rate=50
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:33:05,908 controller 1396628 deployment_state.py:674 - Exception in Replica(id='vvp2unhn', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1460646, ip=10.130.253.103, actor_id=b5753f0f26ea0f55d21a137201000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fa4fc303700>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_);
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:33:05,915 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460467)[0m 2024-08-28 15:33:05,887 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460467)[0m [2024-08-28 15:33:05,887-wetext-en_normalizer-processor.py-build_fst-95-INFO-1460467] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460467)[0m 2024-08-28 15:33:05,888 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460467)[0m [2024-08-28 15:33:05,888-wetext-en_normalizer-processor.py-build_fst-96-INFO-1460467]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460467)[0m 2024-08-28 15:33:05,888 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460467)[0m [2024-08-28 15:33:05,888-wetext-en_normalizer-processor.py-build_fst-97-INFO-1460467] skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460646)[0m 2024-08-28 15:33:05.851742517 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_); 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460646)[0m 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460646)[0m 
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:33:06,038 controller 1396628 deployment_state.py:2228 - Replica(id='vvp2unhn', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1461353)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1461353)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:33:07,864 controller 1396628 deployment_state.py:674 - Exception in Replica(id='z82mc3s1', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1460467, ip=10.130.253.103, actor_id=e232cdb53e2152836fd14c6201000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f0e94735760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 365.68 MiB already allocated; 11.12 MiB free; 366.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:33:07,870 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:33:07,989 controller 1396628 deployment_state.py:2228 - Replica(id='z82mc3s1', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1461353)[0m [2024-08-28 15:33:10,427-root-flow.py-__init__-45-INFO-1461353] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460646)[0m 2024-08-28 15:33:05.521281637 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1460646)[0m 2024-08-28 15:33:05.521329613 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462191)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462191)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1461353)[0m 2024-08-28 15:33:14.707937537 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1461353)[0m 2024-08-28 15:33:14.707977010 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1461353)[0m 2024-08-28 15:33:15,443 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1461353)[0m [2024-08-28 15:33:15,443-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1461353] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1461353)[0m 2024-08-28 15:33:15,443 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1461353)[0m [2024-08-28 15:33:15,443-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1461353]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1461353)[0m 2024-08-28 15:33:15,443 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1461353)[0m [2024-08-28 15:33:15,443-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1461353] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1461353)[0m 2024-08-28 15:33:16,309 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1461353)[0m [2024-08-28 15:33:16,309-wetext-en_normalizer-processor.py-build_fst-95-INFO-1461353] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1461353)[0m 2024-08-28 15:33:16,309 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1461353)[0m [2024-08-28 15:33:16,309-wetext-en_normalizer-processor.py-build_fst-96-INFO-1461353]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1461353)[0m 2024-08-28 15:33:16,309 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1461353)[0m [2024-08-28 15:33:16,309-wetext-en_normalizer-processor.py-build_fst-97-INFO-1461353] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:33:17,909 controller 1396628 deployment_state.py:674 - Exception in Replica(id='vqusg1s0', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1461353, ip=10.130.253.103, actor_id=78c26f88dff0f150450ed2d901000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f38f46ee730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 1.26 MiB already allocated; 7.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:33:17,915 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462446)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462446)[0m   warnings.warn(
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:33:18,036 controller 1396628 deployment_state.py:2228 - Replica(id='vqusg1s0', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462191)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462191)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:33:22,312 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462191)[0m [2024-08-28 15:33:22,761-root-flow.py-__init__-45-INFO-1462191] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1463240)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1463240)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462191)[0m 2024-08-28 15:33:26.869262376 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462191)[0m 2024-08-28 15:33:26.869301081 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462446)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462446)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462191)[0m 2024-08-28 15:33:27,595 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462191)[0m [2024-08-28 15:33:27,595-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1462191] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462191)[0m 2024-08-28 15:33:27,596 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462191)[0m [2024-08-28 15:33:27,596-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1462191]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462191)[0m 2024-08-28 15:33:27,596 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462191)[0m [2024-08-28 15:33:27,596-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1462191] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462191)[0m 2024-08-28 15:33:28,533 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462191)[0m [2024-08-28 15:33:28,533-wetext-en_normalizer-processor.py-build_fst-95-INFO-1462191] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462191)[0m 2024-08-28 15:33:28,533 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462191)[0m [2024-08-28 15:33:28,533-wetext-en_normalizer-processor.py-build_fst-96-INFO-1462191]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462191)[0m 2024-08-28 15:33:28,533 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462191)[0m [2024-08-28 15:33:28,533-wetext-en_normalizer-processor.py-build_fst-97-INFO-1462191] skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1462446)[0m [2024-08-28 15:33:24,447-root-flow.py-__init__-45-INFO-1462446] input frame rate=50
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:33:28,788 controller 1396628 deployment_state.py:674 - Exception in Replica(id='v0t41qq0', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1462446, ip=10.130.253.103, actor_id=16b91f52df51496f2b2dbc6901000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7ff83c075700>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m RuntimeError: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUDA failure 2: out of memory ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=239 ; expr=cudaDeviceSynchronize(); 
[36m(ServeController pid=1396628)[0m 
[36m(ServeController pid=1396628)[0m 
[36m(ServeController pid=1396628)[0m 
[36m(ServeController pid=1396628)[0m The above exception was the direct cause of the following exception:
[36m(ServeController pid=1396628)[0m 
[36m(ServeController pid=1396628)[0m [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1462446, ip=10.130.253.103, actor_id=16b91f52df51496f2b2dbc6901000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7ff83c075700>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 430, in __init__
[36m(ServeController pid=1396628)[0m     raise fallback_error from e
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 425, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(self._fallback_providers, None)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m RuntimeError: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUDA failure 2: out of memory ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=239 ; expr=cudaDeviceSynchronize();
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:33:28,796 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:33:28,921 controller 1396628 deployment_state.py:2228 - Replica(id='v0t41qq0', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:33:30,267 controller 1396628 deployment_state.py:674 - Exception in Replica(id='r7gxpj6y', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1462191, ip=10.130.253.103, actor_id=18d3f233dab136e2f1c6cf8001000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f7ef072e6a0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 31.74 GiB total capacity; 37.29 MiB already allocated; 15.12 MiB free; 38.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:33:30,277 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:33:30,401 controller 1396628 deployment_state.py:2228 - Replica(id='r7gxpj6y', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1463240)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1463240)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1463240)[0m [2024-08-28 15:33:34,271-root-flow.py-__init__-45-INFO-1463240] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464051)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464051)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1463240)[0m 2024-08-28 15:33:38.567470322 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1463240)[0m 2024-08-28 15:33:38.567514762 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1463240)[0m 2024-08-28 15:33:39,300 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1463240)[0m [2024-08-28 15:33:39,300-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1463240] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1463240)[0m 2024-08-28 15:33:39,300 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1463240)[0m [2024-08-28 15:33:39,300-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1463240]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1463240)[0m 2024-08-28 15:33:39,300 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1463240)[0m [2024-08-28 15:33:39,300-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1463240] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1463240)[0m 2024-08-28 15:33:40,203 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1463240)[0m [2024-08-28 15:33:40,203-wetext-en_normalizer-processor.py-build_fst-95-INFO-1463240] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1463240)[0m 2024-08-28 15:33:40,203 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1463240)[0m [2024-08-28 15:33:40,203-wetext-en_normalizer-processor.py-build_fst-96-INFO-1463240]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1463240)[0m 2024-08-28 15:33:40,204 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1463240)[0m [2024-08-28 15:33:40,204-wetext-en_normalizer-processor.py-build_fst-97-INFO-1463240] skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464278)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464278)[0m   warnings.warn(
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:33:41,861 controller 1396628 deployment_state.py:674 - Exception in Replica(id='otio5jdu', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1463240, ip=10.130.253.103, actor_id=80071429fbb21bd3b7ea520c01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7ff600175760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 1.26 MiB already allocated; 1.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:33:41,869 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:33:41,993 controller 1396628 deployment_state.py:2228 - Replica(id='otio5jdu', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464051)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464051)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464051)[0m [2024-08-28 15:33:44,943-root-flow.py-__init__-45-INFO-1464051] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1465271)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1465271)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464278)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464278)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464051)[0m 2024-08-28 15:33:49.008366249 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464051)[0m 2024-08-28 15:33:49.008405921 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464051)[0m 2024-08-28 15:33:49,763 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464051)[0m [2024-08-28 15:33:49,763-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1464051] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464051)[0m 2024-08-28 15:33:49,763 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464051)[0m [2024-08-28 15:33:49,763-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1464051]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464051)[0m 2024-08-28 15:33:49,763 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464051)[0m [2024-08-28 15:33:49,763-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1464051] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464051)[0m 2024-08-28 15:33:50,602 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464051)[0m [2024-08-28 15:33:50,602-wetext-en_normalizer-processor.py-build_fst-95-INFO-1464051] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464051)[0m 2024-08-28 15:33:50,602 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464051)[0m [2024-08-28 15:33:50,602-wetext-en_normalizer-processor.py-build_fst-96-INFO-1464051]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464051)[0m 2024-08-28 15:33:50,602 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464051)[0m [2024-08-28 15:33:50,602-wetext-en_normalizer-processor.py-build_fst-97-INFO-1464051] skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464278)[0m [2024-08-28 15:33:46,413-root-flow.py-__init__-45-INFO-1464278] input frame rate=50
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:33:50,958 controller 1396628 deployment_state.py:674 - Exception in Replica(id='qkm048xt', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1464278, ip=10.130.253.103, actor_id=01328d0ffee4ceed95a7d39601000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f1a546ae760>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_);
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:33:50,965 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464278)[0m 2024-08-28 15:33:50.889834737 [E:onnxruntime:, inference_session.cc:1785 operator()] Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cublasStatus_t; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUBLAS failure 3: CUBLAS_STATUS_ALLOC_FAILED ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=168 ; expr=cublasCreate(&cublas_handle_); 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464278)[0m 
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464278)[0m 
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:33:51,089 controller 1396628 deployment_state.py:2228 - Replica(id='qkm048xt', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeController pid=1396628)[0m WARNING 2024-08-28 15:33:52,412 controller 1396628 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:33:52,899 controller 1396628 deployment_state.py:674 - Exception in Replica(id='x7t5ec8c', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1464051, ip=10.130.253.103, actor_id=cfe499c2e9318893cf85ce3801000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7ff4bc72e730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.74 GiB total capacity; 365.68 MiB already allocated; 13.12 MiB free; 366.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:33:52,907 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:33:53,027 controller 1396628 deployment_state.py:2228 - Replica(id='x7t5ec8c', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1465271)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1465271)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464278)[0m 2024-08-28 15:33:50.556222049 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1464278)[0m 2024-08-28 15:33:50.556257196 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466025)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466025)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1465271)[0m [2024-08-28 15:33:58,481-root-flow.py-__init__-45-INFO-1465271] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1465271)[0m 2024-08-28 15:34:02.864671952 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1465271)[0m 2024-08-28 15:34:02.864712391 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466242)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466242)[0m   warnings.warn(
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:34:03,643 controller 1396628 deployment_state.py:674 - Exception in Replica(id='mz7c4n80', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1465271, ip=10.130.253.103, actor_id=23c78cd1640862aad75bc28101000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7fa68c7356a0>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 56, in __init__
[36m(ServeController pid=1396628)[0m     self.spk2info = torch.load(spk2info, map_location=self.device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location
[36m(ServeController pid=1396628)[0m     return default_restore_location(storage, str(map_location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location
[36m(ServeController pid=1396628)[0m     result = fn(storage, location)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
[36m(ServeController pid=1396628)[0m     return obj.cuda(device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_utils.py", line 81, in _cuda
[36m(ServeController pid=1396628)[0m     untyped_storage = torch.UntypedStorage(
[36m(ServeController pid=1396628)[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 31.74 GiB total capacity; 0 bytes already allocated; 1.12 MiB free; 0 bytes reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:34:03,650 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:34:03,777 controller 1396628 deployment_state.py:2228 - Replica(id='mz7c4n80', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466025)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466025)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466025)[0m [2024-08-28 15:34:07,369-root-flow.py-__init__-45-INFO-1466025] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1467037)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1467037)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466025)[0m 2024-08-28 15:34:11.599396563 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466025)[0m 2024-08-28 15:34:11.599441742 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466242)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466242)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466025)[0m 2024-08-28 15:34:12,747 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466025)[0m [2024-08-28 15:34:12,747-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1466025] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466025)[0m 2024-08-28 15:34:12,747 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466025)[0m [2024-08-28 15:34:12,747-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1466025]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466025)[0m 2024-08-28 15:34:12,747 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466025)[0m [2024-08-28 15:34:12,747-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1466025] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466242)[0m [2024-08-28 15:34:09,315-root-flow.py-__init__-45-INFO-1466242] input frame rate=50
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:34:13,057 controller 1396628 deployment_state.py:674 - Exception in Replica(id='rbhqlytn', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1466242, ip=10.130.253.103, actor_id=2982d12b6ec03fc421a23e0c01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f0d74235670>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 432, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m RuntimeError: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUDA failure 2: out of memory ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=239 ; expr=cudaDeviceSynchronize(); 
[36m(ServeController pid=1396628)[0m 
[36m(ServeController pid=1396628)[0m 
[36m(ServeController pid=1396628)[0m 
[36m(ServeController pid=1396628)[0m The above exception was the direct cause of the following exception:
[36m(ServeController pid=1396628)[0m 
[36m(ServeController pid=1396628)[0m [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1466242, ip=10.130.253.103, actor_id=2982d12b6ec03fc421a23e0c01000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f0d74235670>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 40, in __init__
[36m(ServeController pid=1396628)[0m     self.frontend = CosyVoiceFrontEnd(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/frontend.py", line 54, in __init__
[36m(ServeController pid=1396628)[0m     self.speech_tokenizer_session = onnxruntime.InferenceSession(speech_tokenizer_model, sess_options=option, providers=["CUDAExecutionProvider"if torch.cuda.is_available() else "CPUExecutionProvider"])
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 430, in __init__
[36m(ServeController pid=1396628)[0m     raise fallback_error from e
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 425, in __init__
[36m(ServeController pid=1396628)[0m     self._create_inference_session(self._fallback_providers, None)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 471, in _create_inference_session
[36m(ServeController pid=1396628)[0m     sess.initialize_session(providers, provider_options, disabled_optimizers)
[36m(ServeController pid=1396628)[0m RuntimeError: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:121 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:114 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*, const char*, int) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUDA failure 2: out of memory ; GPU=0 ; hostname=ubuntu ; file=/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_execution_provider.cc ; line=239 ; expr=cudaDeviceSynchronize();
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:34:13,064 controller 1396628 deployment_state.py:1910 - Adding 1 replica to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeController pid=1396628)[0m INFO 2024-08-28 15:34:13,188 controller 1396628 deployment_state.py:2228 - Replica(id='rbhqlytn', deployment='CosyVoiceWsRay', app='app1') is stopped.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466025)[0m 2024-08-28 15:34:13,635 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466025)[0m [2024-08-28 15:34:13,635-wetext-en_normalizer-processor.py-build_fst-95-INFO-1466025] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466025)[0m 2024-08-28 15:34:13,635 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466025)[0m [2024-08-28 15:34:13,635-wetext-en_normalizer-processor.py-build_fst-96-INFO-1466025]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466025)[0m 2024-08-28 15:34:13,636 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1466025)[0m [2024-08-28 15:34:13,636-wetext-en_normalizer-processor.py-build_fst-97-INFO-1466025] skip building fst for en_normalizer ...
[36m(ServeController pid=1396628)[0m ERROR 2024-08-28 15:34:15,263 controller 1396628 deployment_state.py:674 - Exception in Replica(id='sntweeos', deployment='CosyVoiceWsRay', app='app1'), the replica will be stopped.
[36m(ServeController pid=1396628)[0m Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/deployment_state.py", line 672, in check_ready
[36m(ServeController pid=1396628)[0m     _, self._version = ray.get(self._ready_obj_ref)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
[36m(ServeController pid=1396628)[0m     return fn(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
[36m(ServeController pid=1396628)[0m     return func(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 2667, in get
[36m(ServeController pid=1396628)[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/_private/worker.py", line 864, in get_objects
[36m(ServeController pid=1396628)[0m     raise value.as_instanceof_cause()
[36m(ServeController pid=1396628)[0m ray.exceptions.RayTaskError(RuntimeError): [36mray::ServeReplica:app1:CosyVoiceWsRay.initialize_and_get_metadata()[39m (pid=1466025, ip=10.130.253.103, actor_id=abebe08e49c4688ef1474f7001000000, repr=<ray.serve._private.replica.ServeReplica:app1:CosyVoiceWsRay object at 0x7f3ec40b5730>)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 439, in result
[36m(ServeController pid=1396628)[0m     return self.__get_result()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
[36m(ServeController pid=1396628)[0m     raise self._exception
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 609, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     raise RuntimeError(traceback.format_exc()) from None
[36m(ServeController pid=1396628)[0m RuntimeError: Traceback (most recent call last):
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 593, in initialize_and_get_metadata
[36m(ServeController pid=1396628)[0m     await self._user_callable_wrapper.initialize_callable()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 860, in initialize_callable
[36m(ServeController pid=1396628)[0m     await self._call_func_or_gen(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/_private/replica.py", line 826, in _call_func_or_gen
[36m(ServeController pid=1396628)[0m     result = callable(*args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/ray/serve/api.py", line 219, in __init__
[36m(ServeController pid=1396628)[0m     cls.__init__(self, *args, **kwargs)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_ray_server_ws.py", line 82, in __init__
[36m(ServeController pid=1396628)[0m     self.model = CosyVoice(COSYVOICE_MODEL_DIR,device=device)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/server/cosyvoice_model.py", line 55, in __init__
[36m(ServeController pid=1396628)[0m     self.model.load(
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/awesome-ai-projects/tts/CosyVoice/cosyvoice/cli/model.py", line 28, in load
[36m(ServeController pid=1396628)[0m     self.llm.load_state_dict(torch.load(llm_model, map_location=self.device))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 809, in load
[36m(ServeController pid=1396628)[0m     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load
[36m(ServeController pid=1396628)[0m     result = unpickler.load()
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load
[36m(ServeController pid=1396628)[0m     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor
[36m(ServeController pid=1396628)[0m     wrap_storage=restore_location(storage, location),
[36m(ServeController pid=1396628)[0m   File "/home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/serialization.py", line 1086, in restore_location2024-08-28 15:34:25,353	INFO worker.py:1743 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
[36m(ProxyActor pid=1472334)[0m INFO 2024-08-28 15:34:29,602 proxy 10.130.253.103 proxy.py:1160 - Proxy starting on node 8a488fbc27de08335eb1166a6c0cd97d4cfdc341dc83e13face68ab9 (HTTP port: 7001).
[36m(ServeController pid=1472165)[0m INFO 2024-08-28 15:34:29,658 controller 1472165 application_state.py:418 - Building application 'app1'.
[36m(ServeController pid=1472165)[0m INFO 2024-08-28 15:34:34,781 controller 1472165 application_state.py:520 - Built application 'app1' successfully.
[36m(ServeController pid=1472165)[0m INFO 2024-08-28 15:34:34,790 controller 1472165 deployment_state.py:1582 - Deploying new version of Deployment(name='SpeakerEmbeddingsRedisRay', app='app1') (initial target replicas: 10).
[36m(ServeController pid=1472165)[0m INFO 2024-08-28 15:34:34,792 controller 1472165 deployment_state.py:1582 - Deploying new version of Deployment(name='TtsFront', app='app1') (initial target replicas: 10).
[36m(ServeController pid=1472165)[0m INFO 2024-08-28 15:34:34,794 controller 1472165 deployment_state.py:1582 - Deploying new version of Deployment(name='CosyVoiceWsRay', app='app1') (initial target replicas: 16).
[36m(ServeController pid=1472165)[0m INFO 2024-08-28 15:34:34,898 controller 1472165 deployment_state.py:1910 - Adding 10 replicas to Deployment(name='SpeakerEmbeddingsRedisRay', app='app1').
[36m(ServeController pid=1472165)[0m INFO 2024-08-28 15:34:34,913 controller 1472165 deployment_state.py:1910 - Adding 10 replicas to Deployment(name='TtsFront', app='app1').
[36m(ServeController pid=1472165)[0m INFO 2024-08-28 15:34:34,920 controller 1472165 deployment_state.py:1910 - Adding 16 replicas to Deployment(name='CosyVoiceWsRay', app='app1').
[36m(ServeReplica:app1:TtsFront pid=1473470)[0m 2024-08-28 15:34:37,534 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:TtsFront pid=1473470)[0m [2024-08-28 15:34:37,534-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1473470] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:TtsFront pid=1473470)[0m 2024-08-28 15:34:37,534 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:TtsFront pid=1473470)[0m [2024-08-28 15:34:37,534-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1473470]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:TtsFront pid=1473470)[0m 2024-08-28 15:34:37,534 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:TtsFront pid=1473470)[0m [2024-08-28 15:34:37,534-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1473470] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:TtsFront pid=1473470)[0m 2024-08-28 15:34:38,659 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:TtsFront pid=1473470)[0m [2024-08-28 15:34:38,659-wetext-en_normalizer-processor.py-build_fst-95-INFO-1473470] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:TtsFront pid=1473470)[0m 2024-08-28 15:34:38,660 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:TtsFront pid=1473470)[0m [2024-08-28 15:34:38,660-wetext-en_normalizer-processor.py-build_fst-96-INFO-1473470]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:TtsFront pid=1473470)[0m 2024-08-28 15:34:38,660 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:TtsFront pid=1473470)[0m [2024-08-28 15:34:38,660-wetext-en_normalizer-processor.py-build_fst-97-INFO-1473470] skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473513)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473513)[0m   warnings.warn(
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473513)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473513)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
[36m(ServeReplica:app1:TtsFront pid=1473495)[0m 2024-08-28 15:34:37,733 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 9x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)[0m
[36m(ServeReplica:app1:TtsFront pid=1473495)[0m [2024-08-28 15:34:37,733-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1473495] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 9x across cluster][0m
[36m(ServeReplica:app1:TtsFront pid=1473495)[0m 2024-08-28 15:34:37,733 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 9x across cluster][0m
[36m(ServeReplica:app1:TtsFront pid=1473495)[0m [2024-08-28 15:34:37,733-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1473495]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 9x across cluster][0m
[36m(ServeReplica:app1:TtsFront pid=1473495)[0m 2024-08-28 15:34:37,733 WETEXT INFO skip building fst for zh_normalizer ...[32m [repeated 9x across cluster][0m
[36m(ServeReplica:app1:TtsFront pid=1473495)[0m [2024-08-28 15:34:37,733-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1473495] skip building fst for zh_normalizer ...[32m [repeated 9x across cluster][0m
[36m(ServeReplica:app1:TtsFront pid=1473495)[0m 2024-08-28 15:34:38,758 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 9x across cluster][0m
[36m(ServeReplica:app1:TtsFront pid=1473495)[0m [2024-08-28 15:34:38,758-wetext-en_normalizer-processor.py-build_fst-95-INFO-1473495] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 9x across cluster][0m
[36m(ServeReplica:app1:TtsFront pid=1473495)[0m 2024-08-28 15:34:38,759 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 9x across cluster][0m
[36m(ServeReplica:app1:TtsFront pid=1473495)[0m [2024-08-28 15:34:38,759-wetext-en_normalizer-processor.py-build_fst-96-INFO-1473495]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 9x across cluster][0m
[36m(ServeReplica:app1:TtsFront pid=1473495)[0m 2024-08-28 15:34:38,759 WETEXT INFO skip building fst for en_normalizer ...[32m [repeated 9x across cluster][0m
[36m(ServeReplica:app1:TtsFront pid=1473495)[0m [2024-08-28 15:34:38,759-wetext-en_normalizer-processor.py-build_fst-97-INFO-1473495] skip building fst for en_normalizer ...[32m [repeated 9x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473518)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/torch/_jit_internal.py:726: FutureWarning: ignore(True) has been deprecated. TorchScript will now drop the function call on compilation. Use torch.jit.unused now. {}[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473518)[0m   warnings.warn([32m [repeated 7x across cluster][0m[2024-08-28 15:35:17,929 E 1393266 1396625] gcs_rpc_client.h:554: Failed to connect to GCS within 60 seconds. GCS may have been killed. It's either GCS is terminated by `ray stop` or is killed unexpectedly. If it is killed unexpectedly, see the log file gcs_server.out. https://docs.ray.io/en/master/ray-observability/ray-logging.html#logging-directory-structure. The program will terminate.

[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473513)[0m [2024-08-28 15:34:51,282-root-flow.py-__init__-45-INFO-1473513] input frame rate=50
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473513)[0m 2024-08-28 15:34:56.204122364 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473513)[0m 2024-08-28 15:34:56.204168959 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473520)[0m /home/zhanghang/anaconda3/envs/cosy_38/lib/python3.8/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473520)[0m   deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473520)[0m [2024-08-28 15:34:51,605-root-flow.py-__init__-45-INFO-1473520] input frame rate=50[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473513)[0m 2024-08-28 15:34:57,441 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473513)[0m [2024-08-28 15:34:57,441-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1473513] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473513)[0m 2024-08-28 15:34:57,441 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473513)[0m [2024-08-28 15:34:57,441-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1473513]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473513)[0m 2024-08-28 15:34:57,442 WETEXT INFO skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473513)[0m [2024-08-28 15:34:57,442-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1473513] skip building fst for zh_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473513)[0m 2024-08-28 15:34:58,382 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473513)[0m [2024-08-28 15:34:58,382-wetext-en_normalizer-processor.py-build_fst-95-INFO-1473513] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473513)[0m 2024-08-28 15:34:58,382 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473513)[0m [2024-08-28 15:34:58,382-wetext-en_normalizer-processor.py-build_fst-96-INFO-1473513]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473513)[0m 2024-08-28 15:34:58,382 WETEXT INFO skip building fst for en_normalizer ...
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473513)[0m [2024-08-28 15:34:58,382-wetext-en_normalizer-processor.py-build_fst-97-INFO-1473513] skip building fst for en_normalizer ...
[36m(ServeController pid=1472165)[0m WARNING 2024-08-28 15:35:04,958 controller 1472165 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473522)[0m 2024-08-28 15:34:56.353902727 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473522)[0m 2024-08-28 15:34:56.353951218 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473522)[0m 2024-08-28 15:34:57,675 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473522)[0m [2024-08-28 15:34:57,675-wetext-zh_normalizer-processor.py-build_fst-95-INFO-1473522] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_tagger.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473522)[0m 2024-08-28 15:34:57,675 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473522)[0m [2024-08-28 15:34:57,675-wetext-zh_normalizer-processor.py-build_fst-96-INFO-1473522]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/zh_tn_verbalizer.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473522)[0m 2024-08-28 15:34:57,675 WETEXT INFO skip building fst for zh_normalizer ...[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473522)[0m [2024-08-28 15:34:57,675-wetext-zh_normalizer-processor.py-build_fst-97-INFO-1473522] skip building fst for zh_normalizer ...[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473522)[0m 2024-08-28 15:34:58,606 WETEXT INFO found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473522)[0m [2024-08-28 15:34:58,606-wetext-en_normalizer-processor.py-build_fst-95-INFO-1473522] found existing fst: /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_tagger.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473522)[0m 2024-08-28 15:34:58,606 WETEXT INFO                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473522)[0m [2024-08-28 15:34:58,606-wetext-en_normalizer-processor.py-build_fst-96-INFO-1473522]                     /home/zhanghang/awesome-ai-projects/tts/WeTextProcessing/tn/en_tn_verbalizer.fst[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473522)[0m 2024-08-28 15:34:58,606 WETEXT INFO skip building fst for en_normalizer ...[32m [repeated 7x across cluster][0m
[36m(ServeReplica:app1:CosyVoiceWsRay pid=1473522)[0m [2024-08-28 15:34:58,606-wetext-en_normalizer-processor.py-build_fst-97-INFO-1473522] skip building fst for en_normalizer ...[32m [repeated 7x across cluster][0m
[36m(ServeController pid=1472165)[0m WARNING 2024-08-28 15:35:34,961 controller 1472165 deployment_state.py:2193 - Deployment 'CosyVoiceWsRay' in application 'app1' 8 replicas that have taken more than 30s to be scheduled. This may be due to waiting for the cluster to auto-scale or for a runtime environment to be installed. Resources required for each replica: {"CPU": 1.0, "GPU": 0.5}, total resources available: {"CPU": 20.0}. Use `ray status` for more details.[2024-08-28 15:44:04,264 E 1468807 1469466] gcs_rpc_client.h:554: Failed to connect to GCS within 60 seconds. GCS may have been killed. It's either GCS is terminated by `ray stop` or is killed unexpectedly. If it is killed unexpectedly, see the log file gcs_server.out. https://docs.ray.io/en/master/ray-observability/ray-logging.html#logging-directory-structure. The program will terminate.
